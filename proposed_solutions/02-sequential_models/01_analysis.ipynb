{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2960706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 3, 5, 7, 9]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = [0,7,9,1,5,3]\n",
    "L.sort()\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87655094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9003213a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted_indices = [0 3 5 4 1 2]\n",
      "L[sorted_indices] = [0 1 3 5 7 9]\n"
     ]
    }
   ],
   "source": [
    "L = [0,7,9,1,5,3]\n",
    "sorted_indices = np.argsort(L)\n",
    "print(f\"sorted_indices = {sorted_indices}\")\n",
    "print(f\"L[sorted_indices] = {np.array(L)[sorted_indices]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ef5ec",
   "metadata": {},
   "source": [
    "# RNN or Sequential Models in General\n",
    "Sequential models can deal with input of arbitrary length no problem. However, as one dives deeper into conceiving\n",
    "a model, one would soon find out that the implementation details requires some design:\n",
    "\n",
    "01. If we only design a normal sequential model, it will still **suffer from a similar issue** when we wanted to use vanilla NN, i.e. although the input can be now be of arbitrary length, some of the sequential models can only have fixed-length output.\n",
    "  - In our case, i.e. **the output sequence length equals the input sequence length** [The sorted array's length should of course equal the original array's length], two models are particularly suited: **encoder-decoder** and **seq-to-seq** models.\n",
    "  - Seq-to-seq models might\n",
    "02. What kind of output should our sequential model produce?\n",
    "03. What should the loss function look like?\n",
    "04. Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7330c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7e0a7de",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "If we take every array into consideration, how many are there?<br>\n",
    "Well,\n",
    "\n",
    "- for length-2 arrays, there are `10*9` of them\n",
    "- for length-3 arrays, there are `10*9*8` of them\n",
    "- ...\n",
    "- for length-10 arrays, there are $10!$ of them\n",
    "\n",
    "Let's calculate their sum using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf5d2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8ad23d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 9]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10,8,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1395b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9da1262b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(lambda x, y: x*y, range(10,7,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbdfd60",
   "metadata": {},
   "source": [
    "The following cell should give the right number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e71aea1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9864090"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([reduce(lambda x, y: x*y, range(10,10-length,-1))\n",
    "     for length in range(2, 10+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5028dd67",
   "metadata": {},
   "source": [
    "I just wanted to have an estimate of the number of arrays we can have. Now, how should we generate and store our data for training?\n",
    "\n",
    "Let's first try with brute-force. Store the entire dataset into a dictionary with keys as any array and value as the sorted array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b0f7362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2689d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = set(range(0, 9+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be99abe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (0, 4),\n",
       " (0, 5),\n",
       " (0, 6),\n",
       " (0, 7),\n",
       " (0, 8),\n",
       " (0, 9),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (1, 4),\n",
       " (1, 5),\n",
       " (1, 6),\n",
       " (1, 7),\n",
       " (1, 8),\n",
       " (1, 9),\n",
       " (2, 3),\n",
       " (2, 4),\n",
       " (2, 5),\n",
       " (2, 6),\n",
       " (2, 7),\n",
       " (2, 8),\n",
       " (2, 9),\n",
       " (3, 4),\n",
       " (3, 5),\n",
       " (3, 6),\n",
       " (3, 7),\n",
       " (3, 8),\n",
       " (3, 9),\n",
       " (4, 5),\n",
       " (4, 6),\n",
       " (4, 7),\n",
       " (4, 8),\n",
       " (4, 9),\n",
       " (5, 6),\n",
       " (5, 7),\n",
       " (5, 8),\n",
       " (5, 9),\n",
       " (6, 7),\n",
       " (6, 8),\n",
       " (6, 9),\n",
       " (7, 8),\n",
       " (7, 9),\n",
       " (8, 9)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combinations(S, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad546a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 3), (1, 3, 2), (2, 1, 3), (2, 3, 1), (3, 1, 2), (3, 2, 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(permutations([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72920f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123.501"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in [3.14, 2.7281, 123.501]:\n",
    "    pass\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "525dc4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that it returns a list although the input is a tuple\n",
    "sorted((3,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0e3885f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'itertools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'itertools' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# (key, value) of D will be of type (tuple, list)\n",
    "D = {}\n",
    "S = set(range(0, 9+1))\n",
    "for length in range(2, 10+1):\n",
    "    for c in itertools.combinations(S, length):\n",
    "        c_sorted = sorted(c)\n",
    "        for p in permutations(c):\n",
    "            D[p] = c_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69030411",
   "metadata": {},
   "source": [
    "Well, it took less time than I thought, even on an old laptop as Thinkpad X220 (Several seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "724658cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e71ae5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(D) == sum([reduce(lambda x, y: x*y, range(10,10-length,-1))\n",
    "     for length in range(2, 10+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7108c0",
   "metadata": {},
   "source": [
    "To train on sequences of diff lengths, we must **batch sequences of identical lengths together**. This poses a new difficulty..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9585f2",
   "metadata": {},
   "source": [
    "**Rmk**. Let's **use every single one of them as our training set** and **no test set**, because in this particular task, we care less about its generalization ability. If ever later on we care that, we can include arrays of a larger variety of numbers (e.g. all floating point numbers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecb0b5e",
   "metadata": {},
   "source": [
    "Since there are\n",
    "\n",
    "- `10*9` length-2 arrays\n",
    "- `10*9*8` length-3 arrays\n",
    "- ...\n",
    "\n",
    "We can set our batch size to be `10`, a common divisor of all the numbers above.\n",
    "\n",
    "**Rmk**. I have had no prior experience dealing with batches of different lengths of sequences. I referred to [this stackexchange post](https://datascience.stackexchange.com/questions/26366/training-an-rnn-with-examples-of-different-lengths-in-keras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ee2187d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 3, 5, 4]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [1,2,3,4,5,]\n",
    "np.random.shuffle(A)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ed90af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 10, 7, 9, 4, 2, 3, 6, 5]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_lengths = list(range(2, 10+1))\n",
    "np.random.shuffle(shuffled_lengths)\n",
    "shuffled_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d76052a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0e+000, 4.9e-324],\n",
       "       [1.5e-323, 2.5e-323],\n",
       "       [3.5e-323, 4.4e-323]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.empty((3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0719f31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "923fd297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.13682005e-313, 0.00000000e+000, 4.65641493e-310,\n",
       "         0.00000000e+000],\n",
       "        [4.65641493e-310, 0.00000000e+000, 4.65641493e-310,\n",
       "         4.65641493e-310],\n",
       "        [0.00000000e+000, 4.65641493e-310, 0.00000000e+000,\n",
       "         0.00000000e+000]],\n",
       "\n",
       "       [[0.00000000e+000, 1.00000000e+000, 2.00000000e+000,\n",
       "         3.00000000e+000],\n",
       "        [4.00000000e+000, 5.00000000e+000, 6.00000000e+000,\n",
       "         7.00000000e+000],\n",
       "        [8.00000000e+000, 9.00000000e+000, 1.00000000e+001,\n",
       "         1.10000000e+001]],\n",
       "\n",
       "       [[0.00000000e+000, 1.00000000e+000, 2.00000000e+000,\n",
       "         3.00000000e+000],\n",
       "        [4.00000000e+000, 5.00000000e+000, 6.00000000e+000,\n",
       "         7.00000000e+000],\n",
       "        [8.00000000e+000, 9.00000000e+000, 1.00000000e+001,\n",
       "         1.10000000e+001]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.empty((3,3,4))\n",
    "X[1:, ...] = np.arange(3*4).reshape((3,4))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdf3678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(array, depth=n_classes):\n",
    "    \"\"\"\n",
    "    array is an ndarray/list of shape (None,)\n",
    "    \"\"\"\n",
    "    return np.eye(depth)[array, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cf5a01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_sorted = np.array([0, 4, 7 ,9])\n",
    "one_hot(c_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0d6fefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 10), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot(c_sorted, depth=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0515438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def train_generator(batch_size=10):\n",
    "    shuffled_lengths = list(range(2, 10+1))\n",
    "    np.random.shuffle(shuffled_lengths)\n",
    "    for length in shuffled_lengths:\n",
    "        n_instances = reduce(lambda x, y: x*y, range(10,10-length,-1))\n",
    "        X = np.empty((n_instances, length, 1))\n",
    "        Y = np.empty((n_instances, length, n_classes))\n",
    "        n_permutations = math.factorial(length)\n",
    "        #n_combinations = n_instances // n_permutations\n",
    "        for i, c in enumerate(combinations(S, length)):\n",
    "            c_sorted = np.array(sorted(c))  # shape (length,)\n",
    "            c_onehot = one_hot(c_sorted)    # shape (length, n_classes)\n",
    "            Y[i*n_permutations : i*n_permutations + n_permutations, ...] = c_onehot\n",
    "            for j, p in enumerate(permutations(c)):\n",
    "                X[i*n_permutations : i*n_permutations + j, ...] = np.array(p)[..., np.newaxis]\n",
    "        # Throw one batch after another to the model\n",
    "        for k in range(n_instances // batch_size):\n",
    "            yield X[k*batch_size: (k+1)*batch_size].astype(np.float32), Y[k*batch_size: (k+1)*batch_size]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89994ffd",
   "metadata": {},
   "source": [
    "# For testing the above data generator\n",
    "for X, Y in train_generator():\n",
    "    print(f\"X.shape = {X.shape}\")\n",
    "    print(f\"Y.shape = {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddff4fb",
   "metadata": {},
   "source": [
    "## Seq-to-Seq Model\n",
    "This is the seq-to-seq model in which the output sequence's length equals the input sequence length. We had better used **bidirectional RNNs**."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce3facaa",
   "metadata": {},
   "source": [
    "keras.layers.LSTM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae51f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_LSTM_model = keras.models.Sequential([\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(10,\n",
    "        return_sequences=True, input_shape=[None, 1], dropout=0.2)),\n",
    "    keras.layers.LSTM(10, return_sequences=True, dropout=0.2),\n",
    "    #keras.layers.Bidirectional(keras.layers.LSTM(10,\n",
    "    #    return_sequences=True, dropout=0.2)),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(n_classes, activation=\"softmax\")),\n",
    "])\n",
    "\n",
    "#seq2seq_LSTM_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "seq2seq_LSTM_model.compile(loss=\"categorical_crossentropy\",\n",
    "                           optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a76a88",
   "metadata": {},
   "source": [
    "Before we jump into the potentially time-consuming training (via the `fit()` method), we can ask our model make a few predictions first to see if we implemented everything right.\n",
    "01. With `dropout=0.2` in the first layer and predicting on `np.array([0,9,8,3]` produced\n",
    "    ```\n",
    "    TypeError: Input 'b' of 'MatMul' Op has type float32 that does not match type int64 of argument 'a'.\n",
    "    ```\n",
    "    And if we execute the cell again, we will get\n",
    "    ```\n",
    "    TypeError: 'NoneType' object is not callable\n",
    "    ```\n",
    "    Quite weird behaviour.\n",
    "    - Actually, not `dropout=0.2`'s fault, the same error remains when we erase that input arg.\n",
    "02. Once the input has been corrected to an ndarray of `dtype` equal to `float` and the ndarray shape to `n_batches, length (aka n_timesteps), 1`, prediction works no problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad96d316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = seq2seq_LSTM_model.predict(np.array([0.,9,8,3]).reshape((1,4,1)))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9aafc1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = seq2seq_LSTM_model.predict(np.array([0.,9,8,3]).reshape((1,4,1)), batch_size=1)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1b04212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f051f3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 9])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(output[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac1e175a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 0., 3., 2., 9., 8., 5., 1., 6., 7.], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(range(0,9+1), 10, replace=False).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29403053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 4, 10)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = 4\n",
    "bs = 7\n",
    "X_new = np.empty((bs, l, 1))\n",
    "for i in range(X_new.shape[0]):\n",
    "    X_new[i] = np.random.choice(range(0,9+1), l, replace=False).astype(np.float32).reshape((-1, 1))\n",
    "output = seq2seq_LSTM_model.predict(X_new)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3cabe833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.10139951, 0.10696197, 0.10170557, 0.10122366, 0.09184594,\n",
       "         0.09352627, 0.10196288, 0.10176584, 0.10014071, 0.09946768],\n",
       "        [0.10589212, 0.11321083, 0.09876852, 0.10716182, 0.08725755,\n",
       "         0.08694492, 0.09820793, 0.09859796, 0.09694368, 0.10701466],\n",
       "        [0.11091924, 0.11816201, 0.09596454, 0.11186716, 0.08430978,\n",
       "         0.08170394, 0.09514006, 0.09433002, 0.0929394 , 0.11466388],\n",
       "        [0.11462069, 0.12173522, 0.09384915, 0.11450148, 0.08297214,\n",
       "         0.07806396, 0.09311385, 0.09090093, 0.08934669, 0.12089601]],\n",
       "\n",
       "       [[0.10228409, 0.10743177, 0.09990551, 0.10408314, 0.09215908,\n",
       "         0.09249651, 0.09901246, 0.10085864, 0.09895333, 0.10281549],\n",
       "        [0.10832956, 0.11387819, 0.09661565, 0.1100869 , 0.08730229,\n",
       "         0.08573652, 0.09561523, 0.09615359, 0.09502178, 0.11126029],\n",
       "        [0.1102557 , 0.1184758 , 0.09541058, 0.11385911, 0.08402092,\n",
       "         0.08064597, 0.09313145, 0.09470943, 0.09250716, 0.11698385],\n",
       "        [0.11399283, 0.12219117, 0.09343623, 0.11597923, 0.08305788,\n",
       "         0.07710238, 0.09171155, 0.09129731, 0.08866622, 0.12256518]],\n",
       "\n",
       "       [[0.10458932, 0.10794691, 0.09770281, 0.10681712, 0.09215776,\n",
       "         0.09136845, 0.09641731, 0.09810708, 0.0975531 , 0.10734005],\n",
       "        [0.10623193, 0.11383801, 0.09723787, 0.11054865, 0.08687169,\n",
       "         0.08519392, 0.09475781, 0.09796808, 0.09590431, 0.11144774],\n",
       "        [0.1100394 , 0.11863343, 0.09522128, 0.11434339, 0.08443167,\n",
       "         0.08026352, 0.0927288 , 0.09484692, 0.09201037, 0.11748121],\n",
       "        [0.11307079, 0.1222531 , 0.0934559 , 0.11646408, 0.0831898 ,\n",
       "         0.07680407, 0.09106928, 0.09199169, 0.08874767, 0.12295371]],\n",
       "\n",
       "       [[0.10134202, 0.10651454, 0.1023438 , 0.09968857, 0.09199801,\n",
       "         0.09427277, 0.10318915, 0.10154262, 0.10068903, 0.09841946],\n",
       "        [0.10778948, 0.11285012, 0.09815571, 0.10663576, 0.08757518,\n",
       "         0.08745834, 0.09845497, 0.0964042 , 0.09677345, 0.10790277],\n",
       "        [0.10951449, 0.11711924, 0.09671907, 0.11087091, 0.08414283,\n",
       "         0.082588  , 0.09539973, 0.09529086, 0.09470069, 0.1136542 ],\n",
       "        [0.11305018, 0.1206617 , 0.09435922, 0.11396924, 0.08295953,\n",
       "         0.07891063, 0.09331135, 0.09197382, 0.09092654, 0.11987777]],\n",
       "\n",
       "       [[0.10696385, 0.1081648 , 0.09658395, 0.10731581, 0.09220817,\n",
       "         0.09115423, 0.09570083, 0.09560025, 0.09681364, 0.10949448],\n",
       "        [0.10817889, 0.11344378, 0.09610209, 0.11118909, 0.08723643,\n",
       "         0.08533491, 0.09361987, 0.09566291, 0.09529959, 0.11393239],\n",
       "        [0.11218026, 0.11797985, 0.09401149, 0.11474524, 0.0850546 ,\n",
       "         0.08069369, 0.09189067, 0.09250069, 0.09121388, 0.11972965],\n",
       "        [0.1099254 , 0.11891259, 0.0943279 , 0.11520005, 0.08545662,\n",
       "         0.07934642, 0.08988852, 0.09432967, 0.09132487, 0.12128786]],\n",
       "\n",
       "       [[0.10166413, 0.10712925, 0.10076967, 0.10284762, 0.09199744,\n",
       "         0.0930049 , 0.1005317 , 0.10151421, 0.09954081, 0.10100029],\n",
       "        [0.10537078, 0.11344755, 0.09848278, 0.10817795, 0.08699675,\n",
       "         0.08644344, 0.09764674, 0.09915801, 0.09678592, 0.10749005],\n",
       "        [0.1089379 , 0.11844254, 0.09621926, 0.11254447, 0.08389401,\n",
       "         0.08119499, 0.09479381, 0.09610819, 0.09347618, 0.11438873],\n",
       "        [0.11307425, 0.12221469, 0.09379318, 0.11513621, 0.08268521,\n",
       "         0.07757481, 0.09278957, 0.0921704 , 0.08966869, 0.12089293]],\n",
       "\n",
       "       [[0.10303892, 0.10737886, 0.09906777, 0.10484374, 0.09252034,\n",
       "         0.09221709, 0.09787176, 0.09960861, 0.09862629, 0.10482666],\n",
       "        [0.10951799, 0.11367709, 0.0956713 , 0.11020704, 0.08778165,\n",
       "         0.08572625, 0.09481722, 0.09433145, 0.09469566, 0.11357443],\n",
       "        [0.10953436, 0.11640959, 0.09456245, 0.11290348, 0.08601519,\n",
       "         0.08252703, 0.09200644, 0.09429245, 0.09361378, 0.11813524],\n",
       "        [0.10648756, 0.1144857 , 0.09532956, 0.1122578 , 0.08888309,\n",
       "         0.08341971, 0.09067429, 0.09646326, 0.09426913, 0.11772988]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d8bfe1",
   "metadata": {},
   "source": [
    "It's already quite long as a notebook, let's continue the training part in `./02_run01.ipynb`."
   ]
  },
  {
   "cell_type": "raw",
   "id": "726fc2ff",
   "metadata": {},
   "source": [
    "seq2seq_LSTM_model.fit(train_generator(), epochs=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56610a6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f59b69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

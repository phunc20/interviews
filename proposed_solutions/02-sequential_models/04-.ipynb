{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87655094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1395b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "635f3671",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = set(range(0, 9+1))\n",
    "n_classes = 10  # i.e. the array elements are allowed to be 0..9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e71aea1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9864090"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([reduce(lambda x, y: x*y, range(10,10-length,-1))\n",
    "     for length in range(2, 10+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b0f7362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdf3678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(array, depth=n_classes):\n",
    "    \"\"\"\n",
    "    array is an ndarray/list of shape (None,)\n",
    "    \"\"\"\n",
    "    return np.eye(depth)[array, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0515438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def train_generator(batch_size=10):\n",
    "    shuffled_lengths = list(range(2, 10+1))\n",
    "    np.random.shuffle(shuffled_lengths)\n",
    "    for length in shuffled_lengths:\n",
    "        n_instances = reduce(lambda x, y: x*y, range(10,10-length,-1))\n",
    "        X = np.empty((n_instances, length, 1))\n",
    "        Y = np.empty((n_instances, length, n_classes))\n",
    "        n_permutations = math.factorial(length)\n",
    "        #n_combinations = n_instances // n_permutations\n",
    "        for i, c in enumerate(combinations(S, length)):\n",
    "            c_sorted = np.array(sorted(c))  # shape (length,)\n",
    "            c_onehot = one_hot(c_sorted)    # shape (length, n_classes)\n",
    "            Y[i*n_permutations : i*n_permutations + n_permutations, ...] = c_onehot\n",
    "            for j, p in enumerate(permutations(c)):\n",
    "                X[i*n_permutations : i*n_permutations + j, ...] = np.array(p)[..., np.newaxis]\n",
    "        # Throw one batch after another to the model\n",
    "        for k in range(n_instances // batch_size):\n",
    "            yield X[k*batch_size: (k+1)*batch_size].astype(np.float32), Y[k*batch_size: (k+1)*batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddff4fb",
   "metadata": {},
   "source": [
    "## Seq-to-Seq Model\n",
    "This is the seq-to-seq model in which the output sequence's length equals the input sequence length. We had better used **bidirectional RNNs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae51f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_LSTM_model = keras.models.Sequential([\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(7,\n",
    "        return_sequences=True, input_shape=[None, 1], dropout=0.2)),\n",
    "    #keras.layers.LSTM(10, return_sequences=True, dropout=0.2),\n",
    "    #keras.layers.Bidirectional(keras.layers.LSTM(10,\n",
    "    #    return_sequences=True, dropout=0.2)),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(n_classes, activation=\"softmax\")),\n",
    "])\n",
    "\n",
    "#seq2seq_LSTM_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "# sparse_categorical_crossentropy would fail. Cf.\n",
    "# https://stackoverflow.com/questions/49161174/tensorflow-logits-and-labels-must-have-the-same-first-dimension\n",
    "seq2seq_LSTM_model.compile(loss=\"categorical_crossentropy\",\n",
    "                           optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139103cc",
   "metadata": {},
   "source": [
    "Before we jump into the potentially time-consuming training (via the `fit()` method), we can ask our model make a few predictions first to see if we implemented everything right.\n",
    "01. With `dropout=0.2` in the first layer and predicting on `np.array([0,9,8,3]` produced\n",
    "    ```\n",
    "    TypeError: Input 'b' of 'MatMul' Op has type float32 that does not match type int64 of argument 'a'.\n",
    "    ```\n",
    "    And if we execute the cell again, we will get\n",
    "    ```\n",
    "    TypeError: 'NoneType' object is not callable\n",
    "    ```\n",
    "    Quite weird behaviour.\n",
    "    - Actually, not `dropout=0.2`'s fault, the same error remains when we erase that input arg.\n",
    "02. Once the input has been corrected to an ndarray of `dtype` equal to `float` and the ndarray shape to `n_batches, length (aka n_timesteps), 1`, prediction works no problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbd616ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.09104336, 0.09207433, 0.09087513, 0.08971423, 0.10470831,\n",
       "         0.08043717, 0.09903564, 0.08690628, 0.08403429, 0.18117124],\n",
       "        [0.10100501, 0.06889137, 0.1236333 , 0.12173836, 0.1426885 ,\n",
       "         0.09310558, 0.0617233 , 0.05455162, 0.08056537, 0.15209763],\n",
       "        [0.09729038, 0.06632143, 0.14005709, 0.12067135, 0.15129161,\n",
       "         0.09217019, 0.06692744, 0.05764613, 0.07746279, 0.1301616 ],\n",
       "        [0.09301692, 0.06743786, 0.15756966, 0.10293435, 0.14172545,\n",
       "         0.08238933, 0.09952792, 0.07167357, 0.07685323, 0.10687171]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = seq2seq_LSTM_model.predict(np.array([0.,9,8,3]).reshape((1,4,1)), batch_size=1)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a332d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5a535ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 9, 4, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(output[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d09f562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 4, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = 4\n",
    "bs = 7\n",
    "X_new = np.empty((bs, l, 1))\n",
    "for i in range(X_new.shape[0]):\n",
    "    X_new[i] = np.random.choice(range(0,9+1), l, replace=False).astype(np.float32).reshape((-1, 1))\n",
    "output = seq2seq_LSTM_model.predict(X_new)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ebf47b",
   "metadata": {},
   "source": [
    "Let's try the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97fe2494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "twenty-morris",
   "metadata": {},
   "source": [
    "seq2seq_LSTM_model.fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-celebrity",
   "metadata": {},
   "source": [
    "```\n",
    "    steps_per_epoch: Integer or `None`.\n",
    "        Total number of steps (batches of samples)\n",
    "        before declaring one epoch finished and starting the\n",
    "        next epoch. When training with input tensors such as\n",
    "        TensorFlow data tensors, the default `None` is equal to\n",
    "        the number of samples in your dataset divided by\n",
    "        the batch size, or 1 if that cannot be determined. If x is a\n",
    "        `tf.data` dataset, and 'steps_per_epoch'\n",
    "        is None, the epoch will run until the input dataset is exhausted.\n",
    "        When passing an infinitely repeating dataset, you must specify the\n",
    "        `steps_per_epoch` argument. This argument is not supported with\n",
    "        array inputs.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86181021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63513/76000 [========================>.....] - ETA: 38s - loss: 0.2352"
     ]
    }
   ],
   "source": [
    "seq2seq_LSTM_model.fit(train_generator(), \n",
    "                       steps_per_epoch=60000,\n",
    "                       epochs=1,\n",
    "                       verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "broadband-weight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 9, 4, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = seq2seq_LSTM_model.predict(np.array([0.,9,8,3]).reshape((1,4,1)), batch_size=1)\n",
    "np.argmax(output[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-bangkok",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-henry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3f59b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10**4 // 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-narrow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-knitting",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

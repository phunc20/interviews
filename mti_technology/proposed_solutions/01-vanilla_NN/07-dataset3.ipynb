{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ce214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from itertools import combinations, permutations\n",
    "from math import factorial\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f64abbe",
   "metadata": {},
   "source": [
    "## New Ideas\n",
    "- We would like to test on `X_new = np.random.randn(n_new_instances, 10)`. That is, for arrays of arbitrary floating-point numbers like `[0.45, 0.23, -0.08, -1.54, 1.12, -1.82, -1.25, 0.45, -0.39, -0.34]`, we would also like to see how our model's sorting ability is.\n",
    "  - Note that for our vanilla ANN model, the number `10`, i.e. the length of the array, is fixed and has to be fixed. If we want to adapt to all lengths, we might have to resort to RNN.\n",
    "  - This requires a similar but different dataset because in the past we have one-hotize our array elements and now we want the input to be the original, unprocessed array.\n",
    "  - As a consequence, we would probably need to add a preprocessing layer to the new model.\n",
    "- Implement these in `./07-dataset3.ipynb`\n",
    "- Just raw input like `[0.45, 0.23, -0.08, -1.54, 1.12, -1.82, -1.25, 0.45, -0.39, -0.34]`, or should we give the model the indices of each element as well? (To help increase the performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "030d68a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9864090"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CEILING = 10**6\n",
    "FLOOR = -CEILING\n",
    "PADDER = 2*CEILING\n",
    "\n",
    "n_classes = 10\n",
    "max_length = 10\n",
    "n_instances = sum([reduce(lambda x, y: x*y, range(n_classes,n_classes-length,-1)) for length in range(2, max_length+1)])\n",
    "n_instances"
   ]
  },
  {
   "cell_type": "raw",
   "id": "878397d9",
   "metadata": {},
   "source": [
    "help(tf.concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da5f49ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([3., 4.], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([3., 4.])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b01e53bd",
   "metadata": {},
   "source": [
    "x = tf.zeros((10,), dtype=tf.float32)\n",
    "x[:2] = tf.constant([3., 4.])\n",
    "x"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fe1a76d",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "<ipython-input-8-07669b7fcccb> in <module>\n",
    "      1 x = tf.zeros((10,), dtype=tf.float32)\n",
    "----> 2 x[:2] = tf.constant([3., 4.])\n",
    "      3 x\n",
    "\n",
    "TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c688bfaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([3., 4., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.concat([[3., 4.], tf.zeros((8,), dtype=tf.float32)], axis=0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c518676b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4028235e+38"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.float32.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9bfb431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PADDER < tf.float32.max"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d202e389",
   "metadata": {},
   "source": [
    "help(tf.fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b57ca2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([9., 2.], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([9, 2], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeb9d879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([9.e+00, 2.e+00, 2.e+06, 2.e+06, 2.e+06, 2.e+06, 2.e+06, 2.e+06,\n",
       "       2.e+06, 2.e+06], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = [9, 2]\n",
    "x = tf.concat(\n",
    "        [tf.constant(p, dtype=tf.float32),\n",
    "         tf.fill((max_length - len(p),), float(PADDER))],\n",
    "        axis=0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fba11c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.sort_ops.argsort(values, axis=-1, direction='ASCENDING', stable=False, name=None)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argsort"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c540529",
   "metadata": {},
   "source": [
    "help(tf.range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6dd6f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.range(0, 10, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb88b7ba",
   "metadata": {},
   "source": [
    "y = tf.concat((tf.argsort(p),\n",
    "               tf.range(len(p), max_length, dtype=tf.float32)),\n",
    "              axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "74b1bae1",
   "metadata": {},
   "source": [
    "InvalidArgumentError: cannot compute ConcatV2 as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:ConcatV2] name: concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "322258c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 0], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argsort(tf.constant(p, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9d40597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 0], dtype=int32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argsort(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b5a24",
   "metadata": {},
   "source": [
    "The error occurs because `tf.argsort()` always output a tensor of `dtype=tf.int32`"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d8f6927",
   "metadata": {},
   "source": [
    "help(tf.argsort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e065905e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=int32, numpy=array([2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.range(2, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d38337a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=\n",
       "array([-100,  -99,    2,    3,    4,    5,    6,    7,    8,    9],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat(([-100,-99], tf.range(2, max_length)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50085467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_set_generator(test_proportion=0.2):\n",
    "    S = set(range(0, 9+1))\n",
    "    index_instance = 0\n",
    "    for length in range(2, max_length+1):    \n",
    "        for c in combinations(S, length):\n",
    "            for p in permutations(c):\n",
    "                if index_instance % 10 <= 10*test_proportion:\n",
    "                    index_instance += 1\n",
    "                    continue\n",
    "                x = tf.concat(\n",
    "                        [tf.constant(p, dtype=tf.float32),\n",
    "                         tf.fill((max_length - length,), float(PADDER))],\n",
    "                        axis=0)\n",
    "                #y = tf.concat((tf.cast(tf.argsort(p), dtype=tf.float32),\n",
    "                #               tf.range(length, max_length, dtype=tf.float32)))\n",
    "                y = tf.concat((tf.argsort(p), tf.range(length, max_length)), axis=0)\n",
    "                yield x, y\n",
    "                index_instance += 1\n",
    "\n",
    "def test_set_generator(test_proportion=0.2):\n",
    "    S = set(range(0, 9+1))\n",
    "    index_instance = 0\n",
    "    for length in range(2, max_length+1):    \n",
    "        for c in combinations(S, length):\n",
    "            for p in permutations(c):\n",
    "                if index_instance % 10 > 10*test_proportion:\n",
    "                    index_instance += 1\n",
    "                    continue\n",
    "                x = tf.concat(\n",
    "                        [tf.constant(p, dtype=tf.float32),\n",
    "                         tf.fill((max_length - length,), float(PADDER))],\n",
    "                        axis=0)\n",
    "                #y = tf.concat((tf.cast(tf.argsort(p), dtype=tf.float32),\n",
    "                #               tf.range(length, max_length, dtype=tf.float32)))\n",
    "                y = tf.concat((tf.argsort(p), tf.range(length, max_length)), axis=0)\n",
    "                yield x, y\n",
    "                index_instance += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8032645e",
   "metadata": {},
   "source": [
    "It seems that we cannot combine the above two generator functions into a single one because the first arg of `tf.data.Dataset.from_generator()` has to be the generator itself, without parenthese."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5e89b32",
   "metadata": {},
   "source": [
    "def dataset_generator(is_train=True, test_proportion=0.2):\n",
    "    S = set(range(0, 9+1))\n",
    "    index_instance = 0\n",
    "    for length in range(2, max_length+1):    \n",
    "        for c in combinations(S, length):\n",
    "            for p in permutations(c):\n",
    "                if is_train:\n",
    "                    if index_instance % 10 <= 10*test_proportion:\n",
    "                        index_instance += 1\n",
    "                        continue\n",
    "                else:\n",
    "                    if index_instance % 10 > 10*test_proportion:\n",
    "                        index_instance += 1\n",
    "                        continue\n",
    "                x = tf.concat(\n",
    "                        [tf.constant(p, dtype=tf.float32),\n",
    "                         tf.fill((max_length - length,), float(PADDER))],\n",
    "                        axis=0)\n",
    "                #y = tf.concat((tf.cast(tf.argsort(p), dtype=tf.float32),\n",
    "                #               tf.range(length, max_length, dtype=tf.float32)))\n",
    "                y = tf.concat((tf.argsort(p), tf.range(length, max_length)), axis=0)\n",
    "                yield x, y\n",
    "                index_instance += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a13b61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 <= 10*0.2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9fccdfb",
   "metadata": {},
   "source": [
    "train_set = tf.data.Dataset.from_generator(\n",
    "    dataset_generator(is_train=True),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(max_length,), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(max_length,), dtype=tf.int32),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55538cb5",
   "metadata": {},
   "source": [
    "TypeError: `generator` must be callable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "202f6b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_generator(\n",
    "    train_set_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(max_length,), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(max_length,), dtype=tf.int32),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87ab769b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =\n",
      "[2.e+00 0.e+00 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06]\n",
      "y =\n",
      "[1 0 2 3 4 5 6 7 8 9]\n",
      "x =\n",
      "[0.e+00 3.e+00 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06]\n",
      "y =\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "x =\n",
      "[3.e+00 0.e+00 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06]\n",
      "y =\n",
      "[1 0 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_set.take(3):\n",
    "    print(f\"x =\\n{x}\")\n",
    "    print(f\"y =\\n{y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fa3b7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.dtype =\n",
      "<dtype: 'float32'>\n",
      "y.dtype =\n",
      "<dtype: 'int32'>\n",
      "x.dtype =\n",
      "<dtype: 'float32'>\n",
      "y.dtype =\n",
      "<dtype: 'int32'>\n",
      "x.dtype =\n",
      "<dtype: 'float32'>\n",
      "y.dtype =\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_set.take(3):\n",
    "    print(f\"x.dtype =\\n{x.dtype}\")\n",
    "    print(f\"y.dtype =\\n{y.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f3a3128",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = tf.data.Dataset.from_generator(\n",
    "    test_set_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(max_length,), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(max_length,), dtype=tf.int32),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca1efa91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =\n",
      "[0.e+00 1.e+00 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06]\n",
      "y =\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "x =\n",
      "[1.e+00 0.e+00 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06]\n",
      "y =\n",
      "[1 0 2 3 4 5 6 7 8 9]\n",
      "x =\n",
      "[0.e+00 2.e+00 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06 2.e+06]\n",
      "y =\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "for x, y in test_set.take(3):\n",
    "    print(f\"x =\\n{x}\")\n",
    "    print(f\"y =\\n{y}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b59878f0",
   "metadata": {},
   "source": [
    "output_shape = (max_length, max_length)\n",
    "model = keras.models.Sequential([\n",
    "    #keras.layers.Flatten(input_shape=max_length),\n",
    "    keras.layers.Dense(20, input_shape=(max_length,), activation=\"relu\"),\n",
    "    #keras.layers.Dense(40, activation=\"relu\"),\n",
    "    #keras.layers.Dense(np.product(output_shape), activation=\"relu\"),\n",
    "    #keras.layers.Dense(np.product(output_shape)),\n",
    "    keras.layers.Reshape(output_shape),\n",
    "    keras.layers.Softmax(axis=-1),\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"acc\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b7f0eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =\n",
      "(10,)\n",
      "y.shape =\n",
      "(10,)\n",
      "x.shape =\n",
      "(10,)\n",
      "y.shape =\n",
      "(10,)\n",
      "x.shape =\n",
      "(10,)\n",
      "y.shape =\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_set.take(3):\n",
    "    print(f\"x.shape =\\n{x.shape}\")\n",
    "    print(f\"y.shape =\\n{y.shape}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "44f30899",
   "metadata": {},
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"dataset3_ANN.h5\")\n",
    "model.fit(train_set,\n",
    "          batch_size=32,\n",
    "          #validation_split=0.2,\n",
    "          callbacks=[checkpoint_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4989d69b",
   "metadata": {},
   "source": [
    "ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected axis -1 of input shape to have value 10 but received input with shape (10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa157958",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.batch(32, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50739a94",
   "metadata": {},
   "source": [
    "help(model.fit)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4037f67e",
   "metadata": {},
   "source": [
    "Epoch 1/7\n",
    "   4904/Unknown - 191s 39ms/step - loss: 14857.8114 - acc: 0.5291"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f7244b2",
   "metadata": {},
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"dataset3_ANN.h5\")\n",
    "\n",
    "model.fit(train_set,\n",
    "          batch_size=32,\n",
    "          #validation_split=0.2,\n",
    "          epochs=7,\n",
    "          callbacks=[checkpoint_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "385079d8",
   "metadata": {},
   "source": [
    "Epoch 1/7\n",
    "215776/215776 [==============================] - 4829s 22ms/step - loss: 386.6764 - acc: 0.3355\n",
    "Epoch 2/7\n",
    "215776/215776 [==============================] - 4929s 23ms/step - loss: 4599.4030 - acc: 0.3266\n",
    "Epoch 3/7\n",
    "215776/215776 [==============================] - 4760s 22ms/step - loss: 8687.8912 - acc: 0.3039\n",
    "Epoch 4/7\n",
    "215776/215776 [==============================] - 4855s 22ms/step - loss: 13041.7679 - acc: 0.3051\n",
    "Epoch 5/7\n",
    "215776/215776 [==============================] - 4664s 22ms/step - loss: 8915.9849 - acc: 0.3043\n",
    "Epoch 6/7\n",
    "215776/215776 [==============================] - 4748s 22ms/step - loss: 236.1720 - acc: 0.3012\n",
    "Epoch 7/7\n",
    "215776/215776 [==============================] - 4909s 23ms/step - loss: 2.0929 - acc: 0.2915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "607e190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_shape = (max_length, max_length)\n",
    "model = keras.models.Sequential([\n",
    "    #keras.layers.Flatten(input_shape=max_length),\n",
    "    #keras.layers.Dense(20, input_shape=(max_length,), activation=\"relu\"),\n",
    "    keras.layers.Dense(np.product(output_shape),\n",
    "                       input_shape=(max_length,),\n",
    "                       #activation=None,\n",
    "    ),\n",
    "    #keras.layers.Dense(40, activation=\"relu\"),\n",
    "    keras.layers.Dense(np.product(output_shape), activation=\"relu\"),\n",
    "    keras.layers.Dense(np.product(output_shape)),\n",
    "    #keras.layers.Dense(np.product(output_shape), activation=\"tanh\"),\n",
    "    keras.layers.Reshape(output_shape),\n",
    "    keras.layers.Softmax(axis=-1),\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"acc\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f72fdb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1061/Unknown - 77s 71ms/step - loss: 25400.7338 - acc: 0.6178"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-9b7af4bf8be8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0;31m#validation_split=0.2,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"dataset3_ANN.h5\")\n",
    "\n",
    "model.fit(train_set,\n",
    "          batch_size=32,\n",
    "          #validation_split=0.2,\n",
    "          epochs=1,\n",
    "          callbacks=[checkpoint_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656851b0",
   "metadata": {},
   "source": [
    "**(?)** Why `loss` decreases along with `acc` as time goes by?<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f830fdc",
   "metadata": {},
   "source": [
    "## Bad Performance? Improvement.\n",
    "**Rmk.** Usually, the accuracy will start to climb at the beginning of 1st epoch, reaching around `acc = 0.5` before the accuracy stops increasing and starts to decrease. Even when we add multiple dense layers in between, it only helped the model to climb up until `acc = 0.69` (faster, i.e. in fewer steps), and then accuracy starts to decrease (and this time it has more steps to decrease.)\n",
    "\n",
    "Looks like the model had difficulty keeping raising the accuracy. Maybe it's because the model does not know what `PADDER` means. Here are a few improving ideas:\n",
    "\n",
    "01. Assume all array elements are $\\ge 0\\,.$ And pick `PADDER = -1` and hopefully it will better understand what `PADDER` is.\n",
    "  - Add as the input layer of the model an activation layer to render all `-1`'s to `0`'s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e878856d",
   "metadata": {},
   "source": [
    "## Seeing Is Believing\n",
    "Let's watch the sorting in action."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab8273f7",
   "metadata": {},
   "source": [
    "A = [9, 7, 6, 0, 1]\n",
    "#A = np.array([A], dtype=np.float32)\n",
    "A = np.concatenate((A, np.float32.max() * np.ones(max_length - len(A))))\n",
    "A"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4192c57a",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "<ipython-input-41-ad4e313561fa> in <module>\n",
    "      1 A = [9, 7, 6, 0, 1]\n",
    "      2 #A = np.array([A], dtype=np.float32)\n",
    "----> 3 A = np.concatenate((A, np.float32.max() * np.ones(max_length - len(A))))\n",
    "      4 A\n",
    "\n",
    "TypeError: descriptor 'max' of 'numpy.generic' object needs an argument"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a83b7f23",
   "metadata": {},
   "source": [
    "help(np.concatenate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4210657a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<method 'max' of 'numpy.generic' objects>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float32.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "258bb7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method_descriptor"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.float32.max)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cbd0606f",
   "metadata": {},
   "source": [
    "np.float32.max()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fe29cfd",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "<ipython-input-45-79aaa3bf54cb> in <module>\n",
    "----> 1 np.float32.max()\n",
    "\n",
    "TypeError: descriptor 'max' of 'numpy.generic' object needs an argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c8bc023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4028235e+38"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.float32.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ca3206a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7976931348623157e+308"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.finfo('d').max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb476676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4028235e+38"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.finfo('float32').max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "93f7564a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(([1], np.ones(3, dtype=np.float32))).dtype"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6aa7a4e",
   "metadata": {},
   "source": [
    "np.concatenate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3060ee41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [9, 7, 6, 0, 1]\n",
    "A = np.concatenate((A, np.finfo('float32').max * np.ones(max_length - len(A))))\n",
    "A = np.array([A], dtype=np.float32)\n",
    "A.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9d2fa1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1e228d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 5, 0, 8, 1, 3, 7, 2, 9]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(A), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "34775690",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.argmax(model.predict(A), axis=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5bce4fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.0000000e+00, 0.0000000e+00, 3.4028235e+38, 9.0000000e+00,\n",
       "       3.4028235e+38, 7.0000000e+00, 0.0000000e+00, 3.4028235e+38,\n",
       "       6.0000000e+00, 3.4028235e+38], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0][s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2b15ee60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.0000000e+00, 7.0000000e+00, 6.0000000e+00, 0.0000000e+00,\n",
       "        1.0000000e+00, 3.4028235e+38, 3.4028235e+38, 3.4028235e+38,\n",
       "        3.4028235e+38, 3.4028235e+38]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d85680c",
   "metadata": {},
   "source": [
    "def sort(X_batch, correction=False):\n",
    "    \"\"\"\n",
    "    args\n",
    "        X_batch, ndarray of shape (batch_size, max_length)\n",
    "            e.g. [[9, 2, float_max, float_max, ..., float_max],\n",
    "                  [9, 8, 7, 6, 5, 4, 3, 2, 1, 0],\n",
    "                  [6, 1, 2, 9, 4, 5, 3, 7, 0, 8]]\n",
    "            is a case in which batch_size equals 3, max_length equals 10.\n",
    "\n",
    "        correction, bool\n",
    "            sorted_indices, due to the fact that we take only softmax,\n",
    "            can contain repeated and missing indices. If correction == False,\n",
    "            we will not correct this; otherwise, we correct this and make the\n",
    "            indices unique and full-blown.\n",
    "    \n",
    "    return\n",
    "        sorted_arrays, ndarray of shape (batch_size, max_length)\n",
    "            e.g. (if correction=True)\n",
    "                 [[2, 9, float_max, float_max, ..., float_max],\n",
    "                  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
    "    \"\"\"\n",
    "    batch_size, max_length = X_batch.shape\n",
    "    y_pred = model.predict(X_batch)  # shape (batch_size, max_length, max_length)\n",
    "    if not correction:\n",
    "        sorted_indices = np.argmax(y_pred, axis=-1)  # shape (batch_size, max_length)\n",
    "        #sorted_arrays = X_batch[:, sorted_indices]  # wrong\n",
    "        #sorted_arrays = X_batch[range(X_batch.shape[0]), sorted_indices]  # wrong\n",
    "        sorted_arrays = X_batch[np.repeat(np.arange(batch_size), max_length),\n",
    "                                sorted_indices.reshape(-1)\n",
    "                               ].reshape((batch_size, max_length))\n",
    "        return sorted_arrays\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "71b22195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort(X_batch, correction=False):\n",
    "    \"\"\"\n",
    "    args\n",
    "        X_batch, ndarray of shape (batch_size, max_length)\n",
    "            e.g. [[9, 2, float_max, float_max, ..., float_max],\n",
    "                  [9, 8, 7, 6, 5, 4, 3, 2, 1, 0],\n",
    "                  [6, 1, 2, 9, 4, 5, 3, 7, 0, 8]]\n",
    "            is a case in which batch_size equals 3, max_length equals 10.\n",
    "\n",
    "        correction, bool\n",
    "            sorted_indices, due to the fact that we take only softmax,\n",
    "            can contain repeated and missing indices. If correction == False,\n",
    "            we will not correct this; otherwise, we correct this and make the\n",
    "            indices unique and full-blown.\n",
    "    \n",
    "    return\n",
    "        sorted_arrays, ndarray of shape (batch_size, max_length)\n",
    "            e.g. (if correction=True)\n",
    "                 [[2, 9, float_max, float_max, ..., float_max],\n",
    "                  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
    "    \"\"\"\n",
    "    batch_size, max_length = X_batch.shape\n",
    "    y_pred = model.predict(X_batch)  # shape (batch_size, max_length, max_length)\n",
    "    if not correction:\n",
    "        sorted_indices = np.argmax(y_pred, axis=-1)  # shape (batch_size, max_length)\n",
    "    else:\n",
    "        sorted_indices = np.empty((batch_size, max_length), dtype=np.int32)\n",
    "        for k, y_pred_k in enumerate(y_pred):\n",
    "            # y_pred_k.shape equals (max_length, max_length)\n",
    "            sorted_indices[k, 0] = np.argmax(y_pred_k[0])\n",
    "            for i in range(1, max_length):\n",
    "                possible_index = np.argmax(y_pred_k[i])\n",
    "                while possible_index in sorted_indices[k, :i]:\n",
    "                    y_pred_k[i, possible_index] = -1\n",
    "                    possible_index = np.argmax(y_pred_k[i])\n",
    "                sorted_indices[k, i] = possible_index\n",
    "    #sorted_arrays = X_batch[:, sorted_indices]  # wrong\n",
    "    #sorted_arrays = X_batch[range(X_batch.shape[0]), sorted_indices]  # wrong\n",
    "    sorted_arrays = X_batch[np.repeat(np.arange(batch_size), max_length),\n",
    "                            sorted_indices.reshape(-1)\n",
    "                           ].reshape((batch_size, max_length))\n",
    "    return sorted_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5e5eeb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.0000000e+00, 0.0000000e+00, 3.4028235e+38, 9.0000000e+00,\n",
       "        3.4028235e+38, 7.0000000e+00, 0.0000000e+00, 3.4028235e+38,\n",
       "        6.0000000e+00, 3.4028235e+38]], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8aa298b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.0000000e+00, 0.0000000e+00, 3.4028235e+38, 9.0000000e+00,\n",
       "       3.4028235e+38, 7.0000000e+00, 0.0000000e+00, 3.4028235e+38,\n",
       "       6.0000000e+00, 3.4028235e+38], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0][s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7d3a8b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([\n",
    "    [9,8,7,6,5,4,3,2,1,0],\n",
    "    [1,2,3,4,5,9,8,7,0,6],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ce0870da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 2, 4, 6, 9, 5, 3, 2, 8, 0],\n",
       "       [5, 5, 9, 4, 1, 2, 8, 2, 0, 6]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d1a83dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 2, 4, 6, 9, 8, 3, 0, 1, 7],\n",
       "       [5, 2, 9, 4, 1, 0, 8, 7, 6, 3]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort(B, correction=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e735b6fe",
   "metadata": {},
   "source": [
    "Here below is what I have searched to make the function `sort()` work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c8fa08b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = np.arange(3*5).reshape((3,5))\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f022e678",
   "metadata": {},
   "source": [
    "If, say, we want to take\n",
    "\n",
    "- the 1st row with column `0,1,2`\n",
    "- the 2nd row with column `3,0,4`\n",
    "- the 3rd row with column `4,3,2`\n",
    "\n",
    "we can do as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a3f3c603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  8,  5,  9, 14, 13, 12])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[[0,0,0,  1,1,1,  2,2,2], [0,1,2,  3,0,4,  4,3,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2335b977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  8,  5,  9, 14, 13, 12])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[[0,0,0,  1,1,1,  2,2,2], np.ravel([[0,1,2],  [3,0,4],  [4,3,2]])]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92ecab96",
   "metadata": {},
   "source": [
    "help(np.ravel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dac58214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 0, 4, 4, 3, 2])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ravel([[0,1,2],  [3,0,4],  [4,3,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bd14849e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 4, 1, 0, 3, 2, 4, 2])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ravel([[0,1,2],  [3,0,4],  [4,3,2]], order=\"F\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4679427e",
   "metadata": {},
   "source": [
    "dunno which is faster: `reshape` or `ravel`. Or maybe of the same speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f2bc3cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 0, 4, 4, 3, 2])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[0,1,2],  [3,0,4],  [4,3,2]]).reshape((-1,))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40835316",
   "metadata": {},
   "source": [
    "help(np.repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c59833ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(np.arange(3), 4)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c4d953c",
   "metadata": {},
   "source": [
    "help(A.reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "65b5e651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.0000000e+00, 7.0000000e+00, 6.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 3.4028235e+38, 3.4028235e+38, 3.4028235e+38,\n",
       "       3.4028235e+38, 3.4028235e+38], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "54071b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5685bc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -11,   87,  127, -116,   18,   86,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,   80,   13,  100,  -19],\n",
       "       [  23,   86,    0,    0,    0,    0,    0,    0,    0,    0]],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.empty((3, 10), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a51e302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3118f2f6",
   "metadata": {},
   "source": [
    "# `tf.data.Dataset`\n",
    "In previous notebooks, we have this code cell which is a memory hog (the `X`) and took long time to run.\n",
    "Here in this notebook, our objective is to construct the same dataset by using `tf` operations\n",
    "instead of `numpy` ones, hoping to reduce both memory usage and time (i.e. dataset construction time.)\n",
    "```python\n",
    "%%time\n",
    "S = set(range(0, 9+1))\n",
    "index_instance = 0\n",
    "for length in range(2, max_length+1):    \n",
    "    n_permutations = factorial(length)\n",
    "    for c in combinations(S, length):\n",
    "        for p in permutations(c):\n",
    "            X[index_instance, :length, :] = one_hot(np.array(p))\n",
    "            Y[index_instance, :] = np.concatenate((np.argsort(p), np.arange(length, max_length)))\n",
    "            index_instance += 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0f982c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f83f9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e257da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e73becc4",
   "metadata": {},
   "source": [
    "## Workaround\n",
    "Maybe we should abandon the idea of using `tf.data.Dataset.from_tensor_slices(X)`, because that direction might always have to first allocate large memory.\n",
    "\n",
    "We start small and try to use `tf.data.Dataset`'s method to construct an equivalent datset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4531c66",
   "metadata": {},
   "source": [
    "**(?)** You've already seen in `ageron`'s homl2e that a dataset is able to contain tensors of diff shapes. Try to make an example yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc0978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = tf.range(2, max_length+1)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(lengths)\n",
    "dataset = dataset.map(lambda x: tf.range(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74086d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tensor in dataset:\n",
    "    print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14877cb4",
   "metadata": {},
   "source": [
    "**(?)** A big question that you haven't understood is: Should a `tf.data.Dataset` instance contain both `X` and `y`, i.e. data and labels, for supervised training? If so, how do we arrange `X` and `y`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79623c38",
   "metadata": {},
   "source": [
    "### First try: `tf.data.Dataset.from_generator()`\n",
    "As I imagine, we can keep the original code, keep the `for` loop, but instead of filling in each \"row\" of `X`, we make it a generator using the keyword `yield`. After implementing the generator using numpy, we pass the generator into `tf.data.Dataset.from_generator()` and we're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5899c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_generator():\n",
    "    S = set(range(0, 9+1))\n",
    "    index_instance = 0\n",
    "    for length in range(2, max_length+1):    \n",
    "        n_permutations = factorial(length)\n",
    "        for c in combinations(S, length):\n",
    "            for p in permutations(c):\n",
    "                x = np.zeros((max_length, n_classes), dtype=np.float32)\n",
    "                x[:length, :] = tf.one_hot(np.array(p),\n",
    "                                           depth=n_classes).numpy()\n",
    "                y = np.concatenate((np.argsort(p),\n",
    "                                    np.arange(length, max_length)))\n",
    "                yield x, y\n",
    "                index_instance += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b3631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "    dataset_generator,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([max_length, n_classes], [max_length]),\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9476546c",
   "metadata": {},
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "    dataset_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(max_length, n_classes), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(max_length,), dtype=tf.float32),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84b63213",
   "metadata": {},
   "source": [
    "help(tf.data.Dataset.from_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1af744",
   "metadata": {},
   "source": [
    "**Rmk**. Had we forgotten to specify `output_shapes`, the following cells will still be able to run, up until\n",
    "`model.fit()`, which will generate the following error:\n",
    "```\n",
    "ValueError : as_list() is not defined on an unknown TensorShape\n",
    "```\n",
    "`model.fit()` is able to run once we specify both `output_types` and `output_shapes`.\n",
    "\n",
    "In the above, we have also provided (and disactivated) an equivalent cell using `output_signature` instead of the `(output_types, output_shapes)` pair, which is to be deprecated in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2386fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x, y in dataset.take(3):\n",
    "    print(f\"x =\\n{x}\")\n",
    "    print(f\"y =\\n{y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c2b1c0",
   "metadata": {},
   "source": [
    "**Pros**\n",
    "\n",
    "01. We do not have to wait two to six minutes for `X` to be constructed any more\n",
    "02. Computers with little RAM can also run this code. Otherwise, they won't be able to even allocate enough memory for `X`.\n",
    "03. Compared to building a `tf.data.Dataset` completely from its methods, this `from_generator()` has the advantage of being a lot easier to implement. Actually, we almost only replaced the assignment of rows of `X` by `yield`\n",
    "\n",
    "**Cons**\n",
    "\n",
    "01. We must think of a way to split the dataset into Training/Validation/Test sets because we no longer have the entire `X` to apply `train_test_split` from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a26d0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.batch(32, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96068707",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for x, y in dataset.take(3):\n",
    "    print(f\"x.shape =\\n{x.shape}\")\n",
    "    print(f\"y.shape =\\n{y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55731be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/api/layers/reshaping_layers/reshape/\n",
    "#https://keras.io/api/layers/activation_layers/softmax/\n",
    "input_shape = (max_length, n_classes)\n",
    "product_input_shape = np.product((max_length, n_classes))\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=input_shape),\n",
    "    keras.layers.Dense(product_input_shape, activation=\"relu\"),\n",
    "    #keras.layers.Dense(2*product_input_shape, activation=\"relu\"),\n",
    "    keras.layers.Dense(product_input_shape),\n",
    "    keras.layers.Reshape(input_shape),\n",
    "    keras.layers.Softmax(axis=-1),\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"acc\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "662e64db",
   "metadata": {},
   "source": [
    "help(model.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3da33d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"dataset3_ANN.h5\")\n",
    "model.fit(dataset,\n",
    "          batch_size=32,\n",
    "          callbacks=[checkpoint_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8618e5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492a0089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d89d632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26773a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d706a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e16012d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5353cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbdd04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25daf94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d8317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "96735794",
   "metadata": {},
   "source": [
    "def one_hot(array, depth=n_classes):\n",
    "    \"\"\"\n",
    "    array is an ndarray of shape (None,)\n",
    "    \"\"\"\n",
    "    #return tf.one_hot(array, depth=n_classes).numpy()\n",
    "    return np.eye(depth)[array, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff0787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "Y = np.empty((n_instances, max_length), dtype=np.float32)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b8d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#X[...] = 0\n",
    "S = set(range(0, 9+1))\n",
    "index_instance = 0\n",
    "#for length in tqdm(range(2, max_length+1)):\n",
    "for length in range(2, max_length+1):    \n",
    "    n_permutations = factorial(length)\n",
    "    #n_combinations = n_instances // n_permutations\n",
    "    #for i, c in enumerate(combinations(S, length)):\n",
    "    for c in combinations(S, length):\n",
    "        #for j, p in enumerate(permutations(c)):\n",
    "        for p in permutations(c):\n",
    "            #print(f\"(index_instance/n_instances = {index_instance}/{n_instances})\", end=\"\\r\")\n",
    "            #print(f\"np.array(p) = {np.array(p)}\")\n",
    "            X[index_instance, :length, :] = one_hot(np.array(p))#[..., np.newaxis]\n",
    "            Y[index_instance, :] = np.concatenate((np.argsort(p), np.arange(length, max_length)))\n",
    "            index_instance += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae87725",
   "metadata": {},
   "source": [
    "### Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ac10c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db648cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "X_train_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f629d758",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218739e2",
   "metadata": {},
   "source": [
    "We might be able to use less neurons and still arrive at a similar performance. Running out of time, I had not tried to tune the model; instead, I had spent most of the time trying to implement more solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d456c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"vanilla_NN_model.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d73ff0d",
   "metadata": {},
   "source": [
    "# add some callbacks before beginning training.\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"vanilla_NN_model.h5\")\n",
    "\n",
    "model.fit(X_train_val,\n",
    "         Y_train_val,\n",
    "         #steps_per_epoch=60_000,\n",
    "         epochs=3,\n",
    "         validation_split=0.2,\n",
    "         verbose=True,\n",
    "         callbacks=[checkpoint_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b748ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db66b73",
   "metadata": {},
   "source": [
    "## Evaluation on `X_test`\n",
    "We certainly would like to have performance measures like accuracy, precision/recall, etc. But we must first write some convenience functions to facilitate the operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a91c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sorter:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def lenlen(self, x):\n",
    "        somme = np.sum(x, axis=-1)\n",
    "        first_zero_index = -1\n",
    "        for i, s in enumerate(somme):\n",
    "            if s > 10**(-6):\n",
    "                first_zero_index = i\n",
    "        if first_zero_index == -1:\n",
    "            length = 10\n",
    "        else:\n",
    "            length = first_zero_index + 1\n",
    "        return length\n",
    "\n",
    "    def prettier(self, x, y):\n",
    "        \"\"\"\n",
    "        x.shape = (10,10)\n",
    "        \"\"\"\n",
    "        length = self.lenlen(x)\n",
    "        xx = np.argmax(x[:length], axis=-1)\n",
    "        sort_indices = y.astype(int)[:length]\n",
    "        yy = xx[sort_indices]\n",
    "        return xx, yy\n",
    "    \n",
    "    def evaluate(self, X, Y):\n",
    "        Y_pred = self.model.predict(X)  # of shape (n_instances, 10, 10)\n",
    "        Y = Y.astype(int)               # of shape (n_instances, 10)\n",
    "        m = X.shape[0]\n",
    "        n_correct = 0\n",
    "        for i, x in enumerate(X):\n",
    "            length = self.lenlen(x)\n",
    "            y_pred = Y_pred[i]\n",
    "            y_pred_sparse = np.argmax(y_pred, axis=-1)\n",
    "            n_correct += np.array_equal(Y[i], y_pred_sparse)\n",
    "        print(f\"acc = {n_correct/m}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b0a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorter = Sorter(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd637e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sorter.evaluate(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8737cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from itertools import combinations, permutations\n",
    "from math import factorial\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb66cd68",
   "metadata": {},
   "source": [
    "## New Ideas\n",
    "- We would like to test on `X_new = np.random.randn(n_new_instances, 10)`. That is, for arrays of arbitrary floating-point numbers like `[0.45, 0.23, -0.08, -1.54, 1.12, -1.82, -1.25, 0.45, -0.39, -0.34]`, we would also like to see how our model's sorting ability is.\n",
    "  - Note that for our vanilla ANN model, the number `10`, i.e. the length of the array, is fixed and has to be fixed. If we want to adapt to all lengths, we might have to resort to RNN.\n",
    "  - This requires a similar but different dataset because in the past we have one-hotize our array elements and now we want the input to be the original, unprocessed array.\n",
    "  - As a consequence, we would probably need to add a preprocessing layer to the new model.\n",
    "- Implement these in `./07-dataset3.ipynb`\n",
    "- Just raw input like `[0.45, 0.23, -0.08, -1.54, 1.12, -1.82, -1.25, 0.45, -0.39, -0.34]`, or should we give the model the indices of each element as well? (To help increase the performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fda6cbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9864090"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CEILING = 10**6\n",
    "FLOOR = -CEILING\n",
    "PADDER = 2*CEILING\n",
    "\n",
    "n_classes = 10\n",
    "max_length = 10\n",
    "n_instances = sum([reduce(lambda x, y: x*y, range(n_classes,n_classes-length,-1)) for length in range(2, max_length+1)])\n",
    "n_instances"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da6d975e",
   "metadata": {},
   "source": [
    "help(tf.concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0b70f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([3., 4.], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([3., 4.])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14d71ce4",
   "metadata": {},
   "source": [
    "x = tf.zeros((10,), dtype=tf.float32)\n",
    "x[:2] = tf.constant([3., 4.])\n",
    "x"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ea868ae",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "<ipython-input-8-07669b7fcccb> in <module>\n",
    "      1 x = tf.zeros((10,), dtype=tf.float32)\n",
    "----> 2 x[:2] = tf.constant([3., 4.])\n",
    "      3 x\n",
    "\n",
    "TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "651182f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([3., 4., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.concat([[3., 4.], tf.zeros((8,), dtype=tf.float32)], axis=0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9ec5fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4028235e+38"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.float32.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cce0242c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PADDER < tf.float32.max"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da3c4080",
   "metadata": {},
   "source": [
    "help(tf.fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20bb8735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([9., 2.], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([9, 2], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f54b618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([9.e+00, 2.e+00, 2.e+06, 2.e+06, 2.e+06, 2.e+06, 2.e+06, 2.e+06,\n",
       "       2.e+06, 2.e+06], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = [9, 2]\n",
    "x = tf.concat(\n",
    "        [tf.constant(p, dtype=tf.float32),\n",
    "         tf.fill((max_length - len(p),), float(PADDER))],\n",
    "        axis=0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b54d58df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.sort_ops.argsort(values, axis=-1, direction='ASCENDING', stable=False, name=None)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argsort"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c8d87fd",
   "metadata": {},
   "source": [
    "help(tf.range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c48fc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.range(0, 10, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5b20d65",
   "metadata": {},
   "source": [
    "y = tf.concat((tf.argsort(p),\n",
    "               tf.range(len(p), max_length, dtype=tf.float32)),\n",
    "              axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da077df2",
   "metadata": {},
   "source": [
    "InvalidArgumentError: cannot compute ConcatV2 as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:ConcatV2] name: concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a37b586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 0], dtype=int32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argsort(tf.constant(p, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "249d4ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 0], dtype=int32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argsort(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf01aae",
   "metadata": {},
   "source": [
    "The error occurs because `tf.argsort()` always output a tensor of `dtype=tf.int32`"
   ]
  },
  {
   "cell_type": "raw",
   "id": "97ea8910",
   "metadata": {},
   "source": [
    "help(tf.argsort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "babcf73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=int32, numpy=array([2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.range(2, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2582d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_set_generator(test_proportion=0.2):\n",
    "    S = set(range(0, 9+1))\n",
    "    index_instance = 0\n",
    "    for length in range(2, max_length+1):    \n",
    "        for c in combinations(S, length):\n",
    "            for p in permutations(c):\n",
    "                if index_instance % 10 > 10*test_proportion:\n",
    "                    index_instance += 1\n",
    "                    continue\n",
    "                x = tf.concat(\n",
    "                        [tf.constant(p),\n",
    "                         tf.fill((max_length - length,), float(PADDER))],\n",
    "                        axis=0)\n",
    "                #y = tf.concat((tf.cast(tf.argsort(p), dtype=tf.float32),\n",
    "                #               tf.range(length, max_length, dtype=tf.float32)))\n",
    "                y = tf.concat((tf.argsort(p),\n",
    "                               tf.range(length, max_length)))\n",
    "                yield x, y\n",
    "                index_instance += 1\n",
    "\n",
    "def test_set_generator(test_proportion=0.2):\n",
    "    S = set(range(0, 9+1))\n",
    "    index_instance = 0\n",
    "    for length in range(2, max_length+1):    \n",
    "        for c in combinations(S, length):\n",
    "            for p in permutations(c):\n",
    "                if index_instance % 10 <= 10*test_proportion:\n",
    "                    index_instance += 1\n",
    "                    continue\n",
    "                x = tf.concat(\n",
    "                        [tf.constant(p),\n",
    "                         tf.fill((max_length - length,), float(PADDER))],\n",
    "                        axis=0)\n",
    "                #y = tf.concat((tf.cast(tf.argsort(p), dtype=tf.float32),\n",
    "                #               tf.range(length, max_length, dtype=tf.float32)))\n",
    "                y = tf.concat((tf.argsort(p),\n",
    "                               tf.range(length, max_length)))\n",
    "                yield x, y\n",
    "                index_instance += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f20c01ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 <= 10*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b588e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0692cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad1df56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dbf61e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3df0b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf6bb0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c321279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5181d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77ae9381",
   "metadata": {},
   "source": [
    "# `tf.data.Dataset`\n",
    "In previous notebooks, we have this code cell which is a memory hog (the `X`) and took long time to run.\n",
    "Here in this notebook, our objective is to construct the same dataset by using `tf` operations\n",
    "instead of `numpy` ones, hoping to reduce both memory usage and time (i.e. dataset construction time.)\n",
    "```python\n",
    "%%time\n",
    "S = set(range(0, 9+1))\n",
    "index_instance = 0\n",
    "for length in range(2, max_length+1):    \n",
    "    n_permutations = factorial(length)\n",
    "    for c in combinations(S, length):\n",
    "        for p in permutations(c):\n",
    "            X[index_instance, :length, :] = one_hot(np.array(p))\n",
    "            Y[index_instance, :] = np.concatenate((np.argsort(p), np.arange(length, max_length)))\n",
    "            index_instance += 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dbfeaa",
   "metadata": {},
   "source": [
    "## Workaround\n",
    "Maybe we should abandon the idea of using `tf.data.Dataset.from_tensor_slices(X)`, because that direction might always have to first allocate large memory.\n",
    "\n",
    "We start small and try to use `tf.data.Dataset`'s method to construct an equivalent datset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad0a003",
   "metadata": {},
   "source": [
    "**(?)** You've already seen in `ageron`'s homl2e that a dataset is able to contain tensors of diff shapes. Try to make an example yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5fc94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = tf.range(2, max_length+1)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(lengths)\n",
    "dataset = dataset.map(lambda x: tf.range(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e58345fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1], shape=(2,), dtype=int32)\n",
      "tf.Tensor([0 1 2], shape=(3,), dtype=int32)\n",
      "tf.Tensor([0 1 2 3], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int32)\n",
      "tf.Tensor([0 1 2 3 4 5], shape=(6,), dtype=int32)\n",
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([0 1 2 3 4 5 6 7], shape=(8,), dtype=int32)\n",
      "tf.Tensor([0 1 2 3 4 5 6 7 8], shape=(9,), dtype=int32)\n",
      "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for tensor in dataset:\n",
    "    print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b370657c",
   "metadata": {},
   "source": [
    "**(?)** A big question that you haven't understood is: Should a `tf.data.Dataset` instance contain both `X` and `y`, i.e. data and labels, for supervised training? If so, how do we arrange `X` and `y`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fea5a13",
   "metadata": {},
   "source": [
    "### First try: `tf.data.Dataset.from_generator()`\n",
    "As I imagine, we can keep the original code, keep the `for` loop, but instead of filling in each \"row\" of `X`, we make it a generator using the keyword `yield`. After implementing the generator using numpy, we pass the generator into `tf.data.Dataset.from_generator()` and we're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae4e971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_generator():\n",
    "    S = set(range(0, 9+1))\n",
    "    index_instance = 0\n",
    "    for length in range(2, max_length+1):    \n",
    "        n_permutations = factorial(length)\n",
    "        for c in combinations(S, length):\n",
    "            for p in permutations(c):\n",
    "                x = np.zeros((max_length, n_classes), dtype=np.float32)\n",
    "                x[:length, :] = tf.one_hot(np.array(p),\n",
    "                                           depth=n_classes).numpy()\n",
    "                y = np.concatenate((np.argsort(p),\n",
    "                                    np.arange(length, max_length)))\n",
    "                yield x, y\n",
    "                index_instance += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a58c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "    dataset_generator,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([max_length, n_classes], [max_length]),\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec46a20c",
   "metadata": {},
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "    dataset_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(max_length, n_classes), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(max_length,), dtype=tf.float32),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5103c791",
   "metadata": {},
   "source": [
    "help(tf.data.Dataset.from_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b2a9e7",
   "metadata": {},
   "source": [
    "**Rmk**. Had we forgotten to specify `output_shapes`, the following cells will still be able to run, up until\n",
    "`model.fit()`, which will generate the following error:\n",
    "```\n",
    "ValueError : as_list() is not defined on an unknown TensorShape\n",
    "```\n",
    "`model.fit()` is able to run once we specify both `output_types` and `output_shapes`.\n",
    "\n",
    "In the above, we have also provided (and disactivated) an equivalent cell using `output_signature` instead of the `(output_types, output_shapes)` pair, which is to be deprecated in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df6c7886",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "y =\n",
      "[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "x =\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "y =\n",
      "[1. 0. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "x =\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "y =\n",
      "[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(3):\n",
    "    print(f\"x =\\n{x}\")\n",
    "    print(f\"y =\\n{y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d6869b",
   "metadata": {},
   "source": [
    "**Pros**\n",
    "\n",
    "01. We do not have to wait two to six minutes for `X` to be constructed any more\n",
    "02. Computers with little RAM can also run this code. Otherwise, they won't be able to even allocate enough memory for `X`.\n",
    "03. Compared to building a `tf.data.Dataset` completely from its methods, this `from_generator()` has the advantage of being a lot easier to implement. Actually, we almost only replaced the assignment of rows of `X` by `yield`\n",
    "\n",
    "**Cons**\n",
    "\n",
    "01. We must think of a way to split the dataset into Training/Validation/Test sets because we no longer have the entire `X` to apply `train_test_split` from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8aaae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.batch(32, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdeeb1c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =\n",
      "(32, 10, 10)\n",
      "y.shape =\n",
      "(32, 10)\n",
      "x.shape =\n",
      "(32, 10, 10)\n",
      "y.shape =\n",
      "(32, 10)\n",
      "x.shape =\n",
      "(32, 10, 10)\n",
      "y.shape =\n",
      "(32, 10)\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(3):\n",
    "    print(f\"x.shape =\\n{x.shape}\")\n",
    "    print(f\"y.shape =\\n{y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf545ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/api/layers/reshaping_layers/reshape/\n",
    "#https://keras.io/api/layers/activation_layers/softmax/\n",
    "input_shape = (max_length, n_classes)\n",
    "product_input_shape = np.product((max_length, n_classes))\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=input_shape),\n",
    "    keras.layers.Dense(product_input_shape, activation=\"relu\"),\n",
    "    #keras.layers.Dense(2*product_input_shape, activation=\"relu\"),\n",
    "    keras.layers.Dense(product_input_shape),\n",
    "    keras.layers.Reshape(input_shape),\n",
    "    keras.layers.Softmax(axis=-1),\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"acc\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a770788d",
   "metadata": {},
   "source": [
    "help(model.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12fabcf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    310/Unknown - 5s 16ms/step - loss: 1.2368 - acc: 0.6771"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-1e81171595d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#checkpoint_cb = keras.callbacks.ModelCheckpoint(\"vanilla_NN_model_generator.h5\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit(dataset,\n\u001b[0;32m----> 3\u001b[0;31m          batch_size=32)\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/homl2e/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/homl2e/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/homl2e/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/homl2e/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/homl2e/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/homl2e/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.virtualenvs/homl2e/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#checkpoint_cb = keras.callbacks.ModelCheckpoint(\"vanilla_NN_model_generator.h5\")\n",
    "model.fit(dataset,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4167d931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa44e83d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745bba2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8055bdc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb1bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae0558b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4620c041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cafdd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470d4219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a5ffdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "b3881711",
   "metadata": {},
   "source": [
    "def one_hot(array, depth=n_classes):\n",
    "    \"\"\"\n",
    "    array is an ndarray of shape (None,)\n",
    "    \"\"\"\n",
    "    #return tf.one_hot(array, depth=n_classes).numpy()\n",
    "    return np.eye(depth)[array, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "Y = np.empty((n_instances, max_length), dtype=np.float32)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7613eda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#X[...] = 0\n",
    "S = set(range(0, 9+1))\n",
    "index_instance = 0\n",
    "#for length in tqdm(range(2, max_length+1)):\n",
    "for length in range(2, max_length+1):    \n",
    "    n_permutations = factorial(length)\n",
    "    #n_combinations = n_instances // n_permutations\n",
    "    #for i, c in enumerate(combinations(S, length)):\n",
    "    for c in combinations(S, length):\n",
    "        #for j, p in enumerate(permutations(c)):\n",
    "        for p in permutations(c):\n",
    "            #print(f\"(index_instance/n_instances = {index_instance}/{n_instances})\", end=\"\\r\")\n",
    "            #print(f\"np.array(p) = {np.array(p)}\")\n",
    "            X[index_instance, :length, :] = one_hot(np.array(p))#[..., np.newaxis]\n",
    "            Y[index_instance, :] = np.concatenate((np.argsort(p), np.arange(length, max_length)))\n",
    "            index_instance += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21498e90",
   "metadata": {},
   "source": [
    "### Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae94af82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d50ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "X_train_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19955be",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1a5d6e",
   "metadata": {},
   "source": [
    "We might be able to use less neurons and still arrive at a similar performance. Running out of time, I had not tried to tune the model; instead, I had spent most of the time trying to implement more solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ffd4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"vanilla_NN_model.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e987d29",
   "metadata": {},
   "source": [
    "# add some callbacks before beginning training.\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"vanilla_NN_model.h5\")\n",
    "\n",
    "model.fit(X_train_val,\n",
    "         Y_train_val,\n",
    "         #steps_per_epoch=60_000,\n",
    "         epochs=3,\n",
    "         validation_split=0.2,\n",
    "         verbose=True,\n",
    "         callbacks=[checkpoint_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e864829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc19aae",
   "metadata": {},
   "source": [
    "## Evaluation on `X_test`\n",
    "We certainly would like to have performance measures like accuracy, precision/recall, etc. But we must first write some convenience functions to facilitate the operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe99ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sorter:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def lenlen(self, x):\n",
    "        somme = np.sum(x, axis=-1)\n",
    "        first_zero_index = -1\n",
    "        for i, s in enumerate(somme):\n",
    "            if s > 10**(-6):\n",
    "                first_zero_index = i\n",
    "        if first_zero_index == -1:\n",
    "            length = 10\n",
    "        else:\n",
    "            length = first_zero_index + 1\n",
    "        return length\n",
    "\n",
    "    def prettier(self, x, y):\n",
    "        \"\"\"\n",
    "        x.shape = (10,10)\n",
    "        \"\"\"\n",
    "        length = self.lenlen(x)\n",
    "        xx = np.argmax(x[:length], axis=-1)\n",
    "        sort_indices = y.astype(int)[:length]\n",
    "        yy = xx[sort_indices]\n",
    "        return xx, yy\n",
    "    \n",
    "    def evaluate(self, X, Y):\n",
    "        Y_pred = self.model.predict(X)  # of shape (n_instances, 10, 10)\n",
    "        Y = Y.astype(int)               # of shape (n_instances, 10)\n",
    "        m = X.shape[0]\n",
    "        n_correct = 0\n",
    "        for i, x in enumerate(X):\n",
    "            length = self.lenlen(x)\n",
    "            y_pred = Y_pred[i]\n",
    "            y_pred_sparse = np.argmax(y_pred, axis=-1)\n",
    "            n_correct += np.array_equal(Y[i], y_pred_sparse)\n",
    "        print(f\"acc = {n_correct/m}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c2c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorter = Sorter(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37bb68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sorter.evaluate(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

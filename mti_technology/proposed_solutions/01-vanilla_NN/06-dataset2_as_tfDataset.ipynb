{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f24ff32",
   "metadata": {},
   "source": [
    "## `tf.data.Dataset`\n",
    "In previous notebooks, we have this code cell which is a memory hog (the `X`) and took long time to run.\n",
    "Here in this notebook, our objective is to construct the same dataset by using `tf` operations\n",
    "instead of `numpy` ones, hoping to reduce both memory usage and time (i.e. dataset construction time.)\n",
    "```python\n",
    "%%time\n",
    "S = set(range(0, 9+1))\n",
    "index_instance = 0\n",
    "for length in range(2, max_length+1):    \n",
    "    n_permutations = factorial(length)\n",
    "    for c in combinations(S, length):\n",
    "        for p in permutations(c):\n",
    "            X[index_instance, :length, :] = one_hot(np.array(p))\n",
    "            Y[index_instance, :] = np.concatenate((np.argsort(p), np.arange(length, max_length)))\n",
    "            index_instance += 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2963184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from itertools import combinations, permutations\n",
    "from math import factorial\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5497823e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9864090"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = 10\n",
    "max_length = 10\n",
    "n_instances = sum([reduce(lambda x, y: x*y, range(n_classes,n_classes-length,-1)) for length in range(2, max_length+1)])\n",
    "n_instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7652cd90",
   "metadata": {},
   "source": [
    "The following `X` will be our dataset (including training/validation/test sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32857cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function getsizeof in module sys:\n",
      "\n",
      "getsizeof(...)\n",
      "    getsizeof(object, default) -> int\n",
      "    \n",
      "    Return the size of object in bytes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sys.getsizeof)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05180879",
   "metadata": {},
   "source": [
    "X = np.zeros((n_instances, max_length, n_classes), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c987af2",
   "metadata": {},
   "source": [
    "sys.getsizeof(X)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51b53890",
   "metadata": {},
   "source": [
    "3945636128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90a1c2a",
   "metadata": {},
   "source": [
    "`3.9` billion bytes! That's more than `3GB`. Let's verify this number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8af0e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3945636000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_instances * max_length * n_classes * (32//8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136bea7c",
   "metadata": {},
   "source": [
    "**(?)** To dive even deeper: Where went the extra `128` bytes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a049a1",
   "metadata": {},
   "source": [
    "About right: The numbers are quite consistent.\n",
    "\n",
    "By contrast, `tf.zeros` does not allocate the memory immediately, taking only a memory of `184` bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95f1fcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:          3.8Gi       808Mi       2.2Gi       125Mi       789Mi       2.7Gi\r\n",
      "Swap:         975Mi        55Mi       920Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91b12625",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[9864090,10,10] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:Fill]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-564fad5f711e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_instances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2677\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2678\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_zeros_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   2731\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m       \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure it's a vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2733\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2734\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2735\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mfill\u001b[0;34m(dims, value, name)\u001b[0m\n\u001b[1;32m    232\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mend_compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m   \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mfill\u001b[0;34m(dims, value, name)\u001b[0m\n\u001b[1;32m   3314\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3315\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3316\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3317\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3318\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[0;32m~/miniconda3/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.6/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[9864090,10,10] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:Fill]"
     ]
    }
   ],
   "source": [
    "X = tf.zeros((n_instances, max_length, n_classes), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0be0a0c",
   "metadata": {},
   "source": [
    "**(?)** Why my 4GB-RAM Thinkpad X61s still unable to allocate for this `X` using `tf`? Isn't that allocation just a mere 148 bytes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77eeee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93560130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeac898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840795a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c948a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d638b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "0ff84052",
   "metadata": {},
   "source": [
    "def one_hot(array, depth=n_classes):\n",
    "    \"\"\"\n",
    "    array is an ndarray of shape (None,)\n",
    "    \"\"\"\n",
    "    #return tf.one_hot(array, depth=n_classes).numpy()\n",
    "    return np.eye(depth)[array, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d10ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "Y = np.empty((n_instances, max_length), dtype=np.float32)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e16e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#X[...] = 0\n",
    "S = set(range(0, 9+1))\n",
    "index_instance = 0\n",
    "#for length in tqdm(range(2, max_length+1)):\n",
    "for length in range(2, max_length+1):    \n",
    "    n_permutations = factorial(length)\n",
    "    #n_combinations = n_instances // n_permutations\n",
    "    #for i, c in enumerate(combinations(S, length)):\n",
    "    for c in combinations(S, length):\n",
    "        #for j, p in enumerate(permutations(c)):\n",
    "        for p in permutations(c):\n",
    "            #print(f\"(index_instance/n_instances = {index_instance}/{n_instances})\", end=\"\\r\")\n",
    "            #print(f\"np.array(p) = {np.array(p)}\")\n",
    "            X[index_instance, :length, :] = one_hot(np.array(p))#[..., np.newaxis]\n",
    "            Y[index_instance, :] = np.concatenate((np.argsort(p), np.arange(length, max_length)))\n",
    "            index_instance += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453a2740",
   "metadata": {},
   "source": [
    "### Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968ed611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2913c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "X_train_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1c4474",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7ba7b7",
   "metadata": {},
   "source": [
    "We might be able to use less neurons and still arrive at a similar performance. Running out of time, I had not tried to tune the model; instead, I had spent most of the time trying to implement more solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec18921",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"vanilla_NN_model.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43ed25dc",
   "metadata": {},
   "source": [
    "# add some callbacks before beginning training.\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"vanilla_NN_model.h5\")\n",
    "\n",
    "model.fit(X_train_val,\n",
    "         Y_train_val,\n",
    "         #steps_per_epoch=60_000,\n",
    "         epochs=3,\n",
    "         validation_split=0.2,\n",
    "         verbose=True,\n",
    "         callbacks=[checkpoint_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-knowing",
   "metadata": {},
   "source": [
    "## Evaluation on `X_test`\n",
    "We certainly would like to have performance measures like accuracy, precision/recall, etc. But we must first write some convenience functions to facilitate the operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sorter:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def lenlen(self, x):\n",
    "        somme = np.sum(x, axis=-1)\n",
    "        first_zero_index = -1\n",
    "        for i, s in enumerate(somme):\n",
    "            if s > 10**(-6):\n",
    "                first_zero_index = i\n",
    "        if first_zero_index == -1:\n",
    "            length = 10\n",
    "        else:\n",
    "            length = first_zero_index + 1\n",
    "        return length\n",
    "\n",
    "    def prettier(self, x, y):\n",
    "        \"\"\"\n",
    "        x.shape = (10,10)\n",
    "        \"\"\"\n",
    "        length = self.lenlen(x)\n",
    "        xx = np.argmax(x[:length], axis=-1)\n",
    "        sort_indices = y.astype(int)[:length]\n",
    "        yy = xx[sort_indices]\n",
    "        return xx, yy\n",
    "    \n",
    "    def evaluate(self, X, Y):\n",
    "        Y_pred = self.model.predict(X)  # of shape (n_instances, 10, 10)\n",
    "        Y = Y.astype(int)               # of shape (n_instances, 10)\n",
    "        m = X.shape[0]\n",
    "        n_correct = 0\n",
    "        for i, x in enumerate(X):\n",
    "            length = self.lenlen(x)\n",
    "            y_pred = Y_pred[i]\n",
    "            y_pred_sparse = np.argmax(y_pred, axis=-1)\n",
    "            n_correct += np.array_equal(Y[i], y_pred_sparse)\n",
    "        print(f\"acc = {n_correct/m}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorter = Sorter(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-complement",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sorter.evaluate(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

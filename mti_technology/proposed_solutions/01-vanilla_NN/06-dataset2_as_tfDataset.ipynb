{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f24ff32",
   "metadata": {},
   "source": [
    "## `tf.data.Dataset`\n",
    "In previous notebooks, we have this code cell which is a memory hog (the `X`) and took long time to run.\n",
    "Here in this notebook, our objective is to construct the same dataset by using `tf` operations\n",
    "instead of `numpy` ones, hoping to reduce both memory usage and time (i.e. dataset construction time.)\n",
    "```python\n",
    "%%time\n",
    "S = set(range(0, 9+1))\n",
    "index_instance = 0\n",
    "for length in range(2, max_length+1):    \n",
    "    n_permutations = factorial(length)\n",
    "    for c in combinations(S, length):\n",
    "        for p in permutations(c):\n",
    "            X[index_instance, :length, :] = one_hot(np.array(p))\n",
    "            Y[index_instance, :] = np.concatenate((np.argsort(p), np.arange(length, max_length)))\n",
    "            index_instance += 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2963184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from itertools import combinations, permutations\n",
    "from math import factorial\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5497823e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9864090"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = 10\n",
    "max_length = 10\n",
    "n_instances = sum([reduce(lambda x, y: x*y, range(n_classes,n_classes-length,-1)) for length in range(2, max_length+1)])\n",
    "n_instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7652cd90",
   "metadata": {},
   "source": [
    "The following `X` will be our dataset (including training/validation/test sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32857cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function getsizeof in module sys:\n",
      "\n",
      "getsizeof(...)\n",
      "    getsizeof(object, default) -> int\n",
      "    \n",
      "    Return the size of object in bytes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sys.getsizeof)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "27a218a5",
   "metadata": {},
   "source": [
    "X = np.zeros((n_instances, max_length, n_classes), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c987af2",
   "metadata": {},
   "source": [
    "sys.getsizeof(X)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51b53890",
   "metadata": {},
   "source": [
    "3945636128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90a1c2a",
   "metadata": {},
   "source": [
    "`3.9` billion bytes! That's more than `3GB`. Let's verify this number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8af0e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3945636000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_instances * max_length * n_classes * (32//8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136bea7c",
   "metadata": {},
   "source": [
    "**(?)** To dive even deeper: Where went the extra `128` bytes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a049a1",
   "metadata": {},
   "source": [
    "About right: The numbers are quite consistent.\n",
    "\n",
    "By contrast, `tf.zeros` does not allocate the memory immediately, taking only a memory of `184` bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3140b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:          3.8Gi       758Mi       2.1Gi       139Mi       959Mi       2.7Gi\r\n",
      "Swap:         975Mi        54Mi       921Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91b12625",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#X = tf.zeros((n_instances, max_length, n_classes), dtype=tf.float32)\n",
    "# float32 unable to be allocated on 4GB-RAM X61s whereas int8 can.\n",
    "X = tf.zeros((n_instances, max_length, n_classes), dtype=tf.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cf3ca9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:          3.8Gi       1.7Gi       1.2Gi       126Mi       947Mi       1.7Gi\r\n",
      "Swap:         975Mi        54Mi       921Mi\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a396dcf",
   "metadata": {},
   "source": [
    "**(?)** Why my 4GB-RAM Thinkpad X61s still unable to allocate for this `X` using `tf`? Isn't that allocation just a mere 148 bytes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f77eeee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb365017",
   "metadata": {},
   "source": [
    "Note that `free` showed that the RAM consumption after `X = tf.zeros(...)` was around `1GB` whereas `sys.getsizeof(X)` gave only `168B`. Suspicious..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeac898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840795a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c948a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d638b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "0ff84052",
   "metadata": {},
   "source": [
    "def one_hot(array, depth=n_classes):\n",
    "    \"\"\"\n",
    "    array is an ndarray of shape (None,)\n",
    "    \"\"\"\n",
    "    #return tf.one_hot(array, depth=n_classes).numpy()\n",
    "    return np.eye(depth)[array, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d10ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "Y = np.empty((n_instances, max_length), dtype=np.float32)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e16e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#X[...] = 0\n",
    "S = set(range(0, 9+1))\n",
    "index_instance = 0\n",
    "#for length in tqdm(range(2, max_length+1)):\n",
    "for length in range(2, max_length+1):    \n",
    "    n_permutations = factorial(length)\n",
    "    #n_combinations = n_instances // n_permutations\n",
    "    #for i, c in enumerate(combinations(S, length)):\n",
    "    for c in combinations(S, length):\n",
    "        #for j, p in enumerate(permutations(c)):\n",
    "        for p in permutations(c):\n",
    "            #print(f\"(index_instance/n_instances = {index_instance}/{n_instances})\", end=\"\\r\")\n",
    "            #print(f\"np.array(p) = {np.array(p)}\")\n",
    "            X[index_instance, :length, :] = one_hot(np.array(p))#[..., np.newaxis]\n",
    "            Y[index_instance, :] = np.concatenate((np.argsort(p), np.arange(length, max_length)))\n",
    "            index_instance += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453a2740",
   "metadata": {},
   "source": [
    "### Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968ed611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2913c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "X_train_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1c4474",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7ba7b7",
   "metadata": {},
   "source": [
    "We might be able to use less neurons and still arrive at a similar performance. Running out of time, I had not tried to tune the model; instead, I had spent most of the time trying to implement more solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec18921",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"vanilla_NN_model.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43ed25dc",
   "metadata": {},
   "source": [
    "# add some callbacks before beginning training.\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"vanilla_NN_model.h5\")\n",
    "\n",
    "model.fit(X_train_val,\n",
    "         Y_train_val,\n",
    "         #steps_per_epoch=60_000,\n",
    "         epochs=3,\n",
    "         validation_split=0.2,\n",
    "         verbose=True,\n",
    "         callbacks=[checkpoint_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-knowing",
   "metadata": {},
   "source": [
    "## Evaluation on `X_test`\n",
    "We certainly would like to have performance measures like accuracy, precision/recall, etc. But we must first write some convenience functions to facilitate the operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sorter:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def lenlen(self, x):\n",
    "        somme = np.sum(x, axis=-1)\n",
    "        first_zero_index = -1\n",
    "        for i, s in enumerate(somme):\n",
    "            if s > 10**(-6):\n",
    "                first_zero_index = i\n",
    "        if first_zero_index == -1:\n",
    "            length = 10\n",
    "        else:\n",
    "            length = first_zero_index + 1\n",
    "        return length\n",
    "\n",
    "    def prettier(self, x, y):\n",
    "        \"\"\"\n",
    "        x.shape = (10,10)\n",
    "        \"\"\"\n",
    "        length = self.lenlen(x)\n",
    "        xx = np.argmax(x[:length], axis=-1)\n",
    "        sort_indices = y.astype(int)[:length]\n",
    "        yy = xx[sort_indices]\n",
    "        return xx, yy\n",
    "    \n",
    "    def evaluate(self, X, Y):\n",
    "        Y_pred = self.model.predict(X)  # of shape (n_instances, 10, 10)\n",
    "        Y = Y.astype(int)               # of shape (n_instances, 10)\n",
    "        m = X.shape[0]\n",
    "        n_correct = 0\n",
    "        for i, x in enumerate(X):\n",
    "            length = self.lenlen(x)\n",
    "            y_pred = Y_pred[i]\n",
    "            y_pred_sparse = np.argmax(y_pred, axis=-1)\n",
    "            n_correct += np.array_equal(Y[i], y_pred_sparse)\n",
    "        print(f\"acc = {n_correct/m}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorter = Sorter(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-complement",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sorter.evaluate(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f64abbe",
   "metadata": {},
   "source": [
    "# Dataset4\n",
    "This dataset is essentially the same as `../01-vanilla_NN/07-dataset3.ipynb` with the following exceptions:\n",
    "\n",
    "- input to RNN models are still like `[0.45, 0.23, -0.08, -1.54, 1.12, -1.82, -1.25, 0.45, -0.39, -0.34]`, `[1.7435, -3.14159, 2.71827]`, etc.; what is new here is that the number of timesteps of the input can now vary, no longer fixed to `10`\n",
    "  - we no longer need to pad our sequences to a fixed length\n",
    "- we shall use the seq-to-seq model with the same number of time steps for the output as for the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3432a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "max_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5175ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from itertools import combinations, permutations\n",
    "from math import factorial\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cd1b244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9864090"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_instances = sum([reduce(lambda x, y: x*y, range(n_classes,n_classes-length,-1)) for length in range(2, max_length+1)])\n",
    "n_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf6df76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 0.2\n",
    "def train_set_generator(test_proportion=tp):\n",
    "    S = set(range(0, 9+1))\n",
    "    index_instance = 0\n",
    "    for length in range(2, max_length+1):    \n",
    "        for c in combinations(S, length):\n",
    "            for p in permutations(c):\n",
    "                if index_instance % 10 <= 10*test_proportion:\n",
    "                    index_instance += 1\n",
    "                    continue\n",
    "                x = tf.constant(p, dtype=tf.float32)\n",
    "                #x = tf.ragged.constant(p, dtype=tf.float32)\n",
    "                y = tf.argsort(p)\n",
    "                #y = tf.ragged.constant(tf.argsort(p))\n",
    "                yield x, y\n",
    "                index_instance += 1\n",
    "\n",
    "def test_set_generator(test_proportion=tp):\n",
    "    S = set(range(0, 9+1))\n",
    "    index_instance = 0\n",
    "    for length in range(2, max_length+1):    \n",
    "        for c in combinations(S, length):\n",
    "            for p in permutations(c):\n",
    "                if index_instance % 10 > 10*test_proportion:\n",
    "                    index_instance += 1\n",
    "                    continue\n",
    "                x = tf.constant(p, dtype=tf.float32)\n",
    "                y = tf.argsort(p)\n",
    "                yield x, y\n",
    "                index_instance += 1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2b49b10",
   "metadata": {},
   "source": [
    "train_set = tf.data.Dataset.from_generator(\n",
    "    train_set_generator,\n",
    "    output_signature=(\n",
    "        tf.RaggedTensorSpec(shape=(None,), dtype=tf.float32),\n",
    "        tf.RaggedTensorSpec(shape=(None,), dtype=tf.int32),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227660fe",
   "metadata": {},
   "source": [
    "**N.B.** It seems that we needn't use `RaggedTensor` here, because we return at each iteration a normal\n",
    "`Tensor`; what is different is the number of time steps of each iteration's sequence. But this can be\n",
    "handled alone by `tf.data.Dataset.from_generator()` with normal spec `tf.TensorSpec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65b00df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_generator(\n",
    "    train_set_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3e03230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =\n",
      "[2. 0.]\n",
      "y =\n",
      "[1 0]\n",
      "x =\n",
      "[1. 2. 0.]\n",
      "y =\n",
      "[2 0 1]\n",
      "x =\n",
      "[0. 2. 3. 1.]\n",
      "y =\n",
      "[0 3 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Let's show that this generator can really generate tensors of diff shapes\n",
    "prev_time_steps = 1\n",
    "for x, y in train_set.take(1000):\n",
    "    current_time_steps = x.shape[0]\n",
    "    if current_time_steps > prev_time_steps:\n",
    "        print(f\"x =\\n{x}\")\n",
    "        print(f\"y =\\n{y}\")\n",
    "    prev_time_steps = current_time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9187d2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.dtype =\n",
      "<dtype: 'float32'>\n",
      "y.dtype =\n",
      "<dtype: 'int32'>\n",
      "x.dtype =\n",
      "<dtype: 'float32'>\n",
      "y.dtype =\n",
      "<dtype: 'int32'>\n",
      "x.dtype =\n",
      "<dtype: 'float32'>\n",
      "y.dtype =\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_set.take(3):\n",
    "    print(f\"x.dtype =\\n{x.dtype}\")\n",
    "    print(f\"y.dtype =\\n{y.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7e00bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52a6022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = tf.data.Dataset.from_generator(\n",
    "    test_set_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03c2e077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =\n",
      "[0. 1.]\n",
      "y =\n",
      "[0 1]\n",
      "x =\n",
      "[0. 1. 2.]\n",
      "y =\n",
      "[0 1 2]\n",
      "x =\n",
      "[0. 1. 2. 3.]\n",
      "y =\n",
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# Let's show that test set can also generate tensors of diff shapes\n",
    "prev_time_steps = 1\n",
    "for x, y in test_set.take(1000):\n",
    "    current_time_steps = x.shape[0]\n",
    "    if current_time_steps > prev_time_steps:\n",
    "        print(f\"x =\\n{x}\")\n",
    "        print(f\"y =\\n{y}\")\n",
    "    prev_time_steps = current_time_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b4431a",
   "metadata": {},
   "source": [
    "## RNN Model\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6a369b8",
   "metadata": {},
   "source": [
    "dir(keras.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4f11cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, None])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.layers.Input(shape=(None,))\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8a73aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7907d75",
   "metadata": {},
   "source": [
    "I realize that, to produce one-hot-vector-like output at each RNN neuron output, we have to let the model\n",
    "know the number of time steps (i.e. the length of the to-be-sorted array). I guess there are two possible\n",
    "ways to achieve this.\n",
    "\n",
    "01. Somehow extract the number of time steps. I don't know if this is possible in `keras`\n",
    "02. Reconstruct our `tf.data.Dataset` to provide also the number of time steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe0ad67",
   "metadata": {},
   "source": [
    "Let's try the 2nd way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb8f2507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.tensor_shape.TensorShape"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([1,2,3])\n",
    "type(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3faa15a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 0.2\n",
    "def train_set_generator(test_proportion=tp):\n",
    "    S = set(range(0, 9+1))\n",
    "    index_instance = 0\n",
    "    for length in range(2, max_length+1):    \n",
    "        for c in combinations(S, length):\n",
    "            for p in permutations(c):\n",
    "                if index_instance % 10 <= 10*test_proportion:\n",
    "                    index_instance += 1\n",
    "                    continue\n",
    "                #x = tf.ragged.constant(p, dtype=tf.float32)\n",
    "                #x = tf.constant(p, dtype=tf.float32)\n",
    "                X = (tf.constant(p, dtype=tf.float32),\n",
    "                     tf.constant(len(p), dtype=tf.int32))\n",
    "                y = tf.argsort(p)\n",
    "                #y = tf.ragged.constant(tf.argsort(p))\n",
    "                yield X, y\n",
    "                index_instance += 1\n",
    "\n",
    "def test_set_generator(test_proportion=tp):\n",
    "    S = set(range(0, 9+1))\n",
    "    index_instance = 0\n",
    "    for length in range(2, max_length+1):    \n",
    "        for c in combinations(S, length):\n",
    "            for p in permutations(c):\n",
    "                if index_instance % 10 > 10*test_proportion:\n",
    "                    index_instance += 1\n",
    "                    continue\n",
    "                #x = tf.constant(p, dtype=tf.float32)\n",
    "                X = (tf.constant(p, dtype=tf.float32),\n",
    "                     tf.constant(len(p), dtype=tf.int32))\n",
    "                y = tf.argsort(p)\n",
    "                yield X, y\n",
    "                index_instance += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5fb60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_generator(\n",
    "    train_set_generator,\n",
    "    output_signature=(\n",
    "        (tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=(), dtype=tf.float32),),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8696839d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = (<tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 0.], dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=2.0>)\n",
      "y.dtype = <dtype: 'int32'>\n",
      "X = (<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 3.], dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=2.0>)\n",
      "y.dtype = <dtype: 'int32'>\n",
      "X = (<tf.Tensor: shape=(2,), dtype=float32, numpy=array([3., 0.], dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=2.0>)\n",
      "y.dtype = <dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_set.take(3):\n",
    "    print(f\"X = {X}\")\n",
    "    print(f\"y.dtype = {y.dtype}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c803aa5c",
   "metadata": {},
   "source": [
    "#n_time_steps = keras.layers.Input(shape=(), dtype=tf.int32)\n",
    "n_time_steps = keras.layers.Input(shape=(), dtype=np.int32)\n",
    "input_seq = keras.layers.Input(shape=(None, 1), dtype=tf.float32)\n",
    "\n",
    "L1 = keras.layers.LSTM(10, return_sequences=True)\n",
    "o1 = L1(input_seq)\n",
    "#L2 = keras.layers.TimeDistributed(keras.layers.Dense(n_time_steps, activation=\"softmax\"))\n",
    "L2 = keras.layers.Dense(n_time_steps, activation=\"softmax\")\n",
    "o2 = L2(o1)\n",
    "\n",
    "model = keras.Model(inputs=[input_seq, n_time_steps],\n",
    "                    outputs=[o2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbef7017",
   "metadata": {},
   "source": [
    "#### Alert\n",
    "We have to give up the idea of outputing simple one-hot-vector-like sequences, because none of `LSTM`, `Dense`\n",
    "accepts a variable number of neurons (which is in turn because the number of parameters in a layer is fixed).\n",
    "In other words, even if we are with RNNs, we still have to restrict an integer upper bound for the length\n",
    "of our input, to-be-sorted arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "296e4748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d173236",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 10**6\n",
    "L1 = keras.layers.LSTM(10, return_sequences=True)\n",
    "o1 = L1(input_seq)\n",
    "#L2 = keras.layers.TimeDistributed(keras.layers.Dense(n_time_steps, activation=\"softmax\"))\n",
    "L2 = keras.layers.TimeDistributed(keras.layers.Dense(max_length, activation=\"softmax\"))\n",
    "#L2 = keras.layers.Dense(n_time_steps, activation=\"softmax\")\n",
    "o2 = L2(o1)\n",
    "\n",
    "model = keras.Model(inputs=[input_seq, n_time_steps],\n",
    "                    outputs=[o2])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39fb4447",
   "metadata": {},
   "source": [
    "keras.layers.Cropping1D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d7f8d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "?keras.layers.Lambda"
   ]
  },
  {
   "cell_type": "raw",
   "id": "08fedddd",
   "metadata": {},
   "source": [
    "dir(keras.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de733aa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got <tf.Tensor 'Placeholder:0' shape=(None,) dtype=int32>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    987\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_undefined_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m         \u001b[0m_check_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m         \u001b[0mend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_check_index\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;31m# will break `_slice_helper` contract.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SLICE_TYPE_ERROR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", got {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got <KerasTensor: shape=(None,) dtype=int32 (created by layer 'input_19')>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-65889ab2fccd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#L2 = keras.layers.Dense(n_time_steps, activation=\"softmax\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mL2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_time_steps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mo2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m model = keras.Model(inputs=[input_seq, n_time_steps],\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/keras/layers/wrappers.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_mask_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;31m# Shape: (num_samples, timesteps, ...)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training)\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwatch_accessed_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_variable_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreated_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-65889ab2fccd>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#L2 = keras.layers.TimeDistributed(keras.layers.Dense(max_length, activation=\"softmax\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#L2 = keras.layers.Dense(n_time_steps, activation=\"softmax\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mL2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_time_steps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mo2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(op, args, kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m   \"\"\"\n\u001b[1;32m    117\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mdispatcher\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDISPATCH_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mhandle\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m         \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m         for x in nest.flatten([args, kwargs])):\n\u001b[0;32m-> 1538\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mSlicingOpLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1539\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1519\u001b[0m         \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0moriginal_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1522\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[0;31m# Decorate the function to produce this layer's call method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;31m# multiple ops w/ the same name when the layer is reused)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreated_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0mbegin_mask\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_undefined_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m         \u001b[0m_check_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m         \u001b[0mend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.config/miniconda3/envs/homl2e/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_check_index\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0;31m# TODO(slebedev): IndexError seems more appropriate here, but it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;31m# will break `_slice_helper` contract.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SLICE_TYPE_ERROR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", got {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got <tf.Tensor 'Placeholder:0' shape=(None,) dtype=int32>"
     ]
    }
   ],
   "source": [
    "n_time_steps = keras.layers.Input(shape=(), dtype=tf.int32)\n",
    "input_seq = keras.layers.Input(shape=(None,1), dtype=tf.float32)\n",
    "\n",
    "max_length = 10**6\n",
    "L1 = keras.layers.LSTM(10, return_sequences=True)\n",
    "o1 = L1(input_seq)\n",
    "#L2 = keras.layers.TimeDistributed(keras.layers.Dense(n_time_steps, activation=\"softmax\"))\n",
    "#L2 = keras.layers.TimeDistributed(keras.layers.Dense(max_length, activation=\"softmax\"))\n",
    "#L2 = keras.layers.Dense(n_time_steps, activation=\"softmax\")\n",
    "L2 = keras.layers.TimeDistributed(keras.layers.Lambda(lambda x: x[:n_time_steps]))\n",
    "o2 = L2(o1)\n",
    "\n",
    "model = keras.Model(inputs=[input_seq, n_time_steps],\n",
    "                    outputs=[o2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37dd57b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7258ed6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86357a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d7165a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4452ca3d",
   "metadata": {},
   "source": [
    "## New Ideas\n",
    "01. Maybe we can restrict the range of our array elements, say, to $[-1, 1]$ because any array `A` can be always carried into such by dividing by `max(np.abs(A))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99385a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc6c744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f86a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cfff7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a0f5af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a529e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "141ae32d",
   "metadata": {},
   "source": [
    "CEILING = 10**6\n",
    "FLOOR = -CEILING\n",
    "PADDER = 2*CEILING\n",
    "\n",
    "n_classes = 10\n",
    "max_length = 10\n",
    "n_instances = sum([reduce(lambda x, y: x*y, range(n_classes,n_classes-length,-1)) for length in range(2, max_length+1)])\n",
    "n_instances"
   ]
  },
  {
   "cell_type": "raw",
   "id": "878397d9",
   "metadata": {},
   "source": [
    "help(tf.concat)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b01e53bd",
   "metadata": {},
   "source": [
    "x = tf.zeros((10,), dtype=tf.float32)\n",
    "x[:2] = tf.constant([3., 4.])\n",
    "x"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fe1a76d",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "<ipython-input-8-07669b7fcccb> in <module>\n",
    "      1 x = tf.zeros((10,), dtype=tf.float32)\n",
    "----> 2 x[:2] = tf.constant([3., 4.])\n",
    "      3 x\n",
    "\n",
    "TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3aa5b47e",
   "metadata": {},
   "source": [
    "x = tf.concat([[3., 4.], tf.zeros((8,), dtype=tf.float32)], axis=0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c518676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.float32.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bfb431",
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDER < tf.float32.max"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d202e389",
   "metadata": {},
   "source": [
    "help(tf.fill)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca62fdec",
   "metadata": {},
   "source": [
    "tf.argsort(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b5a24",
   "metadata": {},
   "source": [
    "The error occurs because `tf.argsort()` always output a tensor of `dtype=tf.int32`"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d8f6927",
   "metadata": {},
   "source": [
    "help(tf.argsort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e065905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.range(2, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38337a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.concat(([-100,-99], tf.range(2, max_length)), axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b97d5c2",
   "metadata": {},
   "source": [
    "def train_set_generator(test_proportion=0.2):\n",
    "    S = set(range(0, 9+1))\n",
    "    index_instance = 0\n",
    "    for length in range(2, max_length+1):    \n",
    "        for c in combinations(S, length):\n",
    "            for p in permutations(c):\n",
    "                if index_instance % 10 <= 10*test_proportion:\n",
    "                    index_instance += 1\n",
    "                    continue\n",
    "                x = tf.concat(\n",
    "                        [tf.constant(p, dtype=tf.float32),\n",
    "                         tf.fill((max_length - length,), float(PADDER))],\n",
    "                        axis=0)\n",
    "                #y = tf.concat((tf.cast(tf.argsort(p), dtype=tf.float32),\n",
    "                #               tf.range(length, max_length, dtype=tf.float32)))\n",
    "                y = tf.concat((tf.argsort(p), tf.range(length, max_length)), axis=0)\n",
    "                yield x, y\n",
    "                index_instance += 1\n",
    "\n",
    "def test_set_generator(test_proportion=0.2):\n",
    "    S = set(range(0, 9+1))\n",
    "    index_instance = 0\n",
    "    for length in range(2, max_length+1):    \n",
    "        for c in combinations(S, length):\n",
    "            for p in permutations(c):\n",
    "                if index_instance % 10 > 10*test_proportion:\n",
    "                    index_instance += 1\n",
    "                    continue\n",
    "                x = tf.concat(\n",
    "                        [tf.constant(p, dtype=tf.float32),\n",
    "                         tf.fill((max_length - length,), float(PADDER))],\n",
    "                        axis=0)\n",
    "                #y = tf.concat((tf.cast(tf.argsort(p), dtype=tf.float32),\n",
    "                #               tf.range(length, max_length, dtype=tf.float32)))\n",
    "                y = tf.concat((tf.argsort(p), tf.range(length, max_length)), axis=0)\n",
    "                yield x, y\n",
    "                index_instance += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8032645e",
   "metadata": {},
   "source": [
    "It seems that we cannot combine the above two generator functions into a single one because the first arg of `tf.data.Dataset.from_generator()` has to be the generator itself, without parenthese."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5e89b32",
   "metadata": {},
   "source": [
    "def dataset_generator(is_train=True, test_proportion=0.2):\n",
    "    S = set(range(0, 9+1))\n",
    "    index_instance = 0\n",
    "    for length in range(2, max_length+1):    \n",
    "        for c in combinations(S, length):\n",
    "            for p in permutations(c):\n",
    "                if is_train:\n",
    "                    if index_instance % 10 <= 10*test_proportion:\n",
    "                        index_instance += 1\n",
    "                        continue\n",
    "                else:\n",
    "                    if index_instance % 10 > 10*test_proportion:\n",
    "                        index_instance += 1\n",
    "                        continue\n",
    "                x = tf.concat(\n",
    "                        [tf.constant(p, dtype=tf.float32),\n",
    "                         tf.fill((max_length - length,), float(PADDER))],\n",
    "                        axis=0)\n",
    "                #y = tf.concat((tf.cast(tf.argsort(p), dtype=tf.float32),\n",
    "                #               tf.range(length, max_length, dtype=tf.float32)))\n",
    "                y = tf.concat((tf.argsort(p), tf.range(length, max_length)), axis=0)\n",
    "                yield x, y\n",
    "                index_instance += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a13b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 <= 10*0.2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9fccdfb",
   "metadata": {},
   "source": [
    "train_set = tf.data.Dataset.from_generator(\n",
    "    dataset_generator(is_train=True),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(max_length,), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(max_length,), dtype=tf.int32),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55538cb5",
   "metadata": {},
   "source": [
    "TypeError: `generator` must be callable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202f6b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_generator(\n",
    "    train_set_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(max_length,), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(max_length,), dtype=tf.int32),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ab769b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x, y in train_set.take(3):\n",
    "    print(f\"x =\\n{x}\")\n",
    "    print(f\"y =\\n{y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa3b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_set.take(3):\n",
    "    print(f\"x.dtype =\\n{x.dtype}\")\n",
    "    print(f\"y.dtype =\\n{y.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a3128",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = tf.data.Dataset.from_generator(\n",
    "    test_set_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(max_length,), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(max_length,), dtype=tf.int32),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1efa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in test_set.take(3):\n",
    "    print(f\"x =\\n{x}\")\n",
    "    print(f\"y =\\n{y}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b59878f0",
   "metadata": {},
   "source": [
    "output_shape = (max_length, max_length)\n",
    "model = keras.models.Sequential([\n",
    "    #keras.layers.Flatten(input_shape=max_length),\n",
    "    keras.layers.Dense(20, input_shape=(max_length,), activation=\"relu\"),\n",
    "    #keras.layers.Dense(40, activation=\"relu\"),\n",
    "    #keras.layers.Dense(np.product(output_shape), activation=\"relu\"),\n",
    "    #keras.layers.Dense(np.product(output_shape)),\n",
    "    keras.layers.Reshape(output_shape),\n",
    "    keras.layers.Softmax(axis=-1),\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"acc\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f0eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_set.take(3):\n",
    "    print(f\"x.shape =\\n{x.shape}\")\n",
    "    print(f\"y.shape =\\n{y.shape}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "44f30899",
   "metadata": {},
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"dataset3_ANN.h5\")\n",
    "model.fit(train_set,\n",
    "          batch_size=32,\n",
    "          #validation_split=0.2,\n",
    "          callbacks=[checkpoint_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4989d69b",
   "metadata": {},
   "source": [
    "ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected axis -1 of input shape to have value 10 but received input with shape (10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa157958",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.batch(32, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50739a94",
   "metadata": {},
   "source": [
    "help(model.fit)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4037f67e",
   "metadata": {},
   "source": [
    "Epoch 1/7\n",
    "   4904/Unknown - 191s 39ms/step - loss: 14857.8114 - acc: 0.5291"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f7244b2",
   "metadata": {},
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"dataset3_ANN.h5\")\n",
    "\n",
    "model.fit(train_set,\n",
    "          batch_size=32,\n",
    "          #validation_split=0.2,\n",
    "          epochs=7,\n",
    "          callbacks=[checkpoint_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "385079d8",
   "metadata": {},
   "source": [
    "Epoch 1/7\n",
    "215776/215776 [==============================] - 4829s 22ms/step - loss: 386.6764 - acc: 0.3355\n",
    "Epoch 2/7\n",
    "215776/215776 [==============================] - 4929s 23ms/step - loss: 4599.4030 - acc: 0.3266\n",
    "Epoch 3/7\n",
    "215776/215776 [==============================] - 4760s 22ms/step - loss: 8687.8912 - acc: 0.3039\n",
    "Epoch 4/7\n",
    "215776/215776 [==============================] - 4855s 22ms/step - loss: 13041.7679 - acc: 0.3051\n",
    "Epoch 5/7\n",
    "215776/215776 [==============================] - 4664s 22ms/step - loss: 8915.9849 - acc: 0.3043\n",
    "Epoch 6/7\n",
    "215776/215776 [==============================] - 4748s 22ms/step - loss: 236.1720 - acc: 0.3012\n",
    "Epoch 7/7\n",
    "215776/215776 [==============================] - 4909s 23ms/step - loss: 2.0929 - acc: 0.2915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607e190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_shape = (max_length, max_length)\n",
    "model = keras.models.Sequential([\n",
    "    #keras.layers.Flatten(input_shape=max_length),\n",
    "    #keras.layers.Dense(20, input_shape=(max_length,), activation=\"relu\"),\n",
    "    keras.layers.Dense(np.product(output_shape),\n",
    "                       input_shape=(max_length,),\n",
    "                       #activation=None,\n",
    "    ),\n",
    "    #keras.layers.Dense(40, activation=\"relu\"),\n",
    "    keras.layers.Dense(np.product(output_shape), activation=\"relu\"),\n",
    "    keras.layers.Dense(np.product(output_shape)),\n",
    "    #keras.layers.Dense(np.product(output_shape), activation=\"tanh\"),\n",
    "    keras.layers.Reshape(output_shape),\n",
    "    keras.layers.Softmax(axis=-1),\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"acc\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72fdb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"dataset3_ANN.h5\")\n",
    "\n",
    "model.fit(train_set,\n",
    "          batch_size=32,\n",
    "          #validation_split=0.2,\n",
    "          epochs=1,\n",
    "          callbacks=[checkpoint_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656851b0",
   "metadata": {},
   "source": [
    "**(?)** Why `loss` decreases along with `acc` as time goes by?<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f830fdc",
   "metadata": {},
   "source": [
    "## Bad Performance? Improvement.\n",
    "**Rmk.** Usually, the accuracy will start to climb at the beginning of 1st epoch, reaching around `acc = 0.5` before the accuracy stops increasing and starts to decrease. Even when we add multiple dense layers in between, it only helped the model to climb up until `acc = 0.69` (faster, i.e. in fewer steps), and then accuracy starts to decrease (and this time it has more steps to decrease.)\n",
    "\n",
    "Looks like the model had difficulty keeping raising the accuracy. Maybe it's because the model does not know what `PADDER` means. Here are a few improving ideas:\n",
    "\n",
    "01. Assume all array elements are $\\ge 0\\,.$ And pick `PADDER = -1` and hopefully it will better understand what `PADDER` is.\n",
    "  - Add as the input layer of the model an activation layer to render all `-1`'s to `0`'s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e878856d",
   "metadata": {},
   "source": [
    "## Seeing Is Believing\n",
    "Let's watch the sorting in action."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab8273f7",
   "metadata": {},
   "source": [
    "A = [9, 7, 6, 0, 1]\n",
    "#A = np.array([A], dtype=np.float32)\n",
    "A = np.concatenate((A, np.float32.max() * np.ones(max_length - len(A))))\n",
    "A"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4192c57a",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "<ipython-input-41-ad4e313561fa> in <module>\n",
    "      1 A = [9, 7, 6, 0, 1]\n",
    "      2 #A = np.array([A], dtype=np.float32)\n",
    "----> 3 A = np.concatenate((A, np.float32.max() * np.ones(max_length - len(A))))\n",
    "      4 A\n",
    "\n",
    "TypeError: descriptor 'max' of 'numpy.generic' object needs an argument"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a83b7f23",
   "metadata": {},
   "source": [
    "help(np.concatenate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4210657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.float32.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258bb7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(np.float32.max)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cbd0606f",
   "metadata": {},
   "source": [
    "np.float32.max()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fe29cfd",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "<ipython-input-45-79aaa3bf54cb> in <module>\n",
    "----> 1 np.float32.max()\n",
    "\n",
    "TypeError: descriptor 'max' of 'numpy.generic' object needs an argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8bc023",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.float32.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca3206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.finfo('d').max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb476676",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.finfo('float32').max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f7564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(([1], np.ones(3, dtype=np.float32))).dtype"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6aa7a4e",
   "metadata": {},
   "source": [
    "np.concatenate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3060ee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [9, 7, 6, 0, 1]\n",
    "A = np.concatenate((A, np.finfo('float32').max * np.ones(max_length - len(A))))\n",
    "A = np.array([A], dtype=np.float32)\n",
    "A.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2fa1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e228d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(model.predict(A), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34775690",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.argmax(model.predict(A), axis=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bce4fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "A[0][s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b15ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d85680c",
   "metadata": {},
   "source": [
    "def sort(X_batch, correction=False):\n",
    "    \"\"\"\n",
    "    args\n",
    "        X_batch, ndarray of shape (batch_size, max_length)\n",
    "            e.g. [[9, 2, float_max, float_max, ..., float_max],\n",
    "                  [9, 8, 7, 6, 5, 4, 3, 2, 1, 0],\n",
    "                  [6, 1, 2, 9, 4, 5, 3, 7, 0, 8]]\n",
    "            is a case in which batch_size equals 3, max_length equals 10.\n",
    "\n",
    "        correction, bool\n",
    "            sorted_indices, due to the fact that we take only softmax,\n",
    "            can contain repeated and missing indices. If correction == False,\n",
    "            we will not correct this; otherwise, we correct this and make the\n",
    "            indices unique and full-blown.\n",
    "    \n",
    "    return\n",
    "        sorted_arrays, ndarray of shape (batch_size, max_length)\n",
    "            e.g. (if correction=True)\n",
    "                 [[2, 9, float_max, float_max, ..., float_max],\n",
    "                  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
    "    \"\"\"\n",
    "    batch_size, max_length = X_batch.shape\n",
    "    y_pred = model.predict(X_batch)  # shape (batch_size, max_length, max_length)\n",
    "    if not correction:\n",
    "        sorted_indices = np.argmax(y_pred, axis=-1)  # shape (batch_size, max_length)\n",
    "        #sorted_arrays = X_batch[:, sorted_indices]  # wrong\n",
    "        #sorted_arrays = X_batch[range(X_batch.shape[0]), sorted_indices]  # wrong\n",
    "        sorted_arrays = X_batch[np.repeat(np.arange(batch_size), max_length),\n",
    "                                sorted_indices.reshape(-1)\n",
    "                               ].reshape((batch_size, max_length))\n",
    "        return sorted_arrays\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b22195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort(X_batch, correction=False):\n",
    "    \"\"\"\n",
    "    args\n",
    "        X_batch, ndarray of shape (batch_size, max_length)\n",
    "            e.g. [[9, 2, float_max, float_max, ..., float_max],\n",
    "                  [9, 8, 7, 6, 5, 4, 3, 2, 1, 0],\n",
    "                  [6, 1, 2, 9, 4, 5, 3, 7, 0, 8]]\n",
    "            is a case in which batch_size equals 3, max_length equals 10.\n",
    "\n",
    "        correction, bool\n",
    "            sorted_indices, due to the fact that we take only softmax,\n",
    "            can contain repeated and missing indices. If correction == False,\n",
    "            we will not correct this; otherwise, we correct this and make the\n",
    "            indices unique and full-blown.\n",
    "    \n",
    "    return\n",
    "        sorted_arrays, ndarray of shape (batch_size, max_length)\n",
    "            e.g. (if correction=True)\n",
    "                 [[2, 9, float_max, float_max, ..., float_max],\n",
    "                  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
    "    \"\"\"\n",
    "    batch_size, max_length = X_batch.shape\n",
    "    y_pred = model.predict(X_batch)  # shape (batch_size, max_length, max_length)\n",
    "    if not correction:\n",
    "        sorted_indices = np.argmax(y_pred, axis=-1)  # shape (batch_size, max_length)\n",
    "    else:\n",
    "        sorted_indices = np.empty((batch_size, max_length), dtype=np.int32)\n",
    "        for k, y_pred_k in enumerate(y_pred):\n",
    "            # y_pred_k.shape equals (max_length, max_length)\n",
    "            sorted_indices[k, 0] = np.argmax(y_pred_k[0])\n",
    "            for i in range(1, max_length):\n",
    "                possible_index = np.argmax(y_pred_k[i])\n",
    "                while possible_index in sorted_indices[k, :i]:\n",
    "                    y_pred_k[i, possible_index] = -1\n",
    "                    possible_index = np.argmax(y_pred_k[i])\n",
    "                sorted_indices[k, i] = possible_index\n",
    "    #sorted_arrays = X_batch[:, sorted_indices]  # wrong\n",
    "    #sorted_arrays = X_batch[range(X_batch.shape[0]), sorted_indices]  # wrong\n",
    "    sorted_arrays = X_batch[np.repeat(np.arange(batch_size), max_length),\n",
    "                            sorted_indices.reshape(-1)\n",
    "                           ].reshape((batch_size, max_length))\n",
    "    return sorted_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5eeb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa298b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "A[0][s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3a8b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([\n",
    "    [9,8,7,6,5,4,3,2,1,0],\n",
    "    [1,2,3,4,5,9,8,7,0,6],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0870da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a83dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort(B, correction=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e735b6fe",
   "metadata": {},
   "source": [
    "Here below is what I have searched to make the function `sort()` work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa08b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.arange(3*5).reshape((3,5))\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f022e678",
   "metadata": {},
   "source": [
    "If, say, we want to take\n",
    "\n",
    "- the 1st row with column `0,1,2`\n",
    "- the 2nd row with column `3,0,4`\n",
    "- the 3rd row with column `4,3,2`\n",
    "\n",
    "we can do as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f3c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "C[[0,0,0,  1,1,1,  2,2,2], [0,1,2,  3,0,4,  4,3,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2335b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "C[[0,0,0,  1,1,1,  2,2,2], np.ravel([[0,1,2],  [3,0,4],  [4,3,2]])]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92ecab96",
   "metadata": {},
   "source": [
    "help(np.ravel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac58214",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ravel([[0,1,2],  [3,0,4],  [4,3,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd14849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ravel([[0,1,2],  [3,0,4],  [4,3,2]], order=\"F\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4679427e",
   "metadata": {},
   "source": [
    "dunno which is faster: `reshape` or `ravel`. Or maybe of the same speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc3cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[0,1,2],  [3,0,4],  [4,3,2]]).reshape((-1,))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40835316",
   "metadata": {},
   "source": [
    "help(np.repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59833ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.repeat(np.arange(3), 4)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c4d953c",
   "metadata": {},
   "source": [
    "help(A.reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b5e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54071b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(10).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5685bc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.empty((3, 10), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a51e302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3118f2f6",
   "metadata": {},
   "source": [
    "# `tf.data.Dataset`\n",
    "In previous notebooks, we have this code cell which is a memory hog (the `X`) and took long time to run.\n",
    "Here in this notebook, our objective is to construct the same dataset by using `tf` operations\n",
    "instead of `numpy` ones, hoping to reduce both memory usage and time (i.e. dataset construction time.)\n",
    "```python\n",
    "%%time\n",
    "S = set(range(0, 9+1))\n",
    "index_instance = 0\n",
    "for length in range(2, max_length+1):    \n",
    "    n_permutations = factorial(length)\n",
    "    for c in combinations(S, length):\n",
    "        for p in permutations(c):\n",
    "            X[index_instance, :length, :] = one_hot(np.array(p))\n",
    "            Y[index_instance, :] = np.concatenate((np.argsort(p), np.arange(length, max_length)))\n",
    "            index_instance += 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0f982c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f83f9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e257da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e73becc4",
   "metadata": {},
   "source": [
    "## Workaround\n",
    "Maybe we should abandon the idea of using `tf.data.Dataset.from_tensor_slices(X)`, because that direction might always have to first allocate large memory.\n",
    "\n",
    "We start small and try to use `tf.data.Dataset`'s method to construct an equivalent datset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4531c66",
   "metadata": {},
   "source": [
    "**(?)** You've already seen in `ageron`'s homl2e that a dataset is able to contain tensors of diff shapes. Try to make an example yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc0978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = tf.range(2, max_length+1)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(lengths)\n",
    "dataset = dataset.map(lambda x: tf.range(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74086d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tensor in dataset:\n",
    "    print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14877cb4",
   "metadata": {},
   "source": [
    "**(?)** A big question that you haven't understood is: Should a `tf.data.Dataset` instance contain both `X` and `y`, i.e. data and labels, for supervised training? If so, how do we arrange `X` and `y`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79623c38",
   "metadata": {},
   "source": [
    "### First try: `tf.data.Dataset.from_generator()`\n",
    "As I imagine, we can keep the original code, keep the `for` loop, but instead of filling in each \"row\" of `X`, we make it a generator using the keyword `yield`. After implementing the generator using numpy, we pass the generator into `tf.data.Dataset.from_generator()` and we're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5899c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_generator():\n",
    "    S = set(range(0, 9+1))\n",
    "    index_instance = 0\n",
    "    for length in range(2, max_length+1):    \n",
    "        n_permutations = factorial(length)\n",
    "        for c in combinations(S, length):\n",
    "            for p in permutations(c):\n",
    "                x = np.zeros((max_length, n_classes), dtype=np.float32)\n",
    "                x[:length, :] = tf.one_hot(np.array(p),\n",
    "                                           depth=n_classes).numpy()\n",
    "                y = np.concatenate((np.argsort(p),\n",
    "                                    np.arange(length, max_length)))\n",
    "                yield x, y\n",
    "                index_instance += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b3631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "    dataset_generator,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([max_length, n_classes], [max_length]),\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9476546c",
   "metadata": {},
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "    dataset_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(max_length, n_classes), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(max_length,), dtype=tf.float32),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84b63213",
   "metadata": {},
   "source": [
    "help(tf.data.Dataset.from_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1af744",
   "metadata": {},
   "source": [
    "**Rmk**. Had we forgotten to specify `output_shapes`, the following cells will still be able to run, up until\n",
    "`model.fit()`, which will generate the following error:\n",
    "```\n",
    "ValueError : as_list() is not defined on an unknown TensorShape\n",
    "```\n",
    "`model.fit()` is able to run once we specify both `output_types` and `output_shapes`.\n",
    "\n",
    "In the above, we have also provided (and disactivated) an equivalent cell using `output_signature` instead of the `(output_types, output_shapes)` pair, which is to be deprecated in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2386fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x, y in dataset.take(3):\n",
    "    print(f\"x =\\n{x}\")\n",
    "    print(f\"y =\\n{y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c2b1c0",
   "metadata": {},
   "source": [
    "**Pros**\n",
    "\n",
    "01. We do not have to wait two to six minutes for `X` to be constructed any more\n",
    "02. Computers with little RAM can also run this code. Otherwise, they won't be able to even allocate enough memory for `X`.\n",
    "03. Compared to building a `tf.data.Dataset` completely from its methods, this `from_generator()` has the advantage of being a lot easier to implement. Actually, we almost only replaced the assignment of rows of `X` by `yield`\n",
    "\n",
    "**Cons**\n",
    "\n",
    "01. We must think of a way to split the dataset into Training/Validation/Test sets because we no longer have the entire `X` to apply `train_test_split` from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a26d0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.batch(32, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96068707",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for x, y in dataset.take(3):\n",
    "    print(f\"x.shape =\\n{x.shape}\")\n",
    "    print(f\"y.shape =\\n{y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55731be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/api/layers/reshaping_layers/reshape/\n",
    "#https://keras.io/api/layers/activation_layers/softmax/\n",
    "input_shape = (max_length, n_classes)\n",
    "product_input_shape = np.product((max_length, n_classes))\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=input_shape),\n",
    "    keras.layers.Dense(product_input_shape, activation=\"relu\"),\n",
    "    #keras.layers.Dense(2*product_input_shape, activation=\"relu\"),\n",
    "    keras.layers.Dense(product_input_shape),\n",
    "    keras.layers.Reshape(input_shape),\n",
    "    keras.layers.Softmax(axis=-1),\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"acc\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "662e64db",
   "metadata": {},
   "source": [
    "help(model.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3da33d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"dataset3_ANN.h5\")\n",
    "model.fit(dataset,\n",
    "          batch_size=32,\n",
    "          callbacks=[checkpoint_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8618e5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492a0089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d89d632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26773a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d706a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e16012d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5353cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbdd04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25daf94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d8317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "96735794",
   "metadata": {},
   "source": [
    "def one_hot(array, depth=n_classes):\n",
    "    \"\"\"\n",
    "    array is an ndarray of shape (None,)\n",
    "    \"\"\"\n",
    "    #return tf.one_hot(array, depth=n_classes).numpy()\n",
    "    return np.eye(depth)[array, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff0787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "Y = np.empty((n_instances, max_length), dtype=np.float32)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b8d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#X[...] = 0\n",
    "S = set(range(0, 9+1))\n",
    "index_instance = 0\n",
    "#for length in tqdm(range(2, max_length+1)):\n",
    "for length in range(2, max_length+1):    \n",
    "    n_permutations = factorial(length)\n",
    "    #n_combinations = n_instances // n_permutations\n",
    "    #for i, c in enumerate(combinations(S, length)):\n",
    "    for c in combinations(S, length):\n",
    "        #for j, p in enumerate(permutations(c)):\n",
    "        for p in permutations(c):\n",
    "            #print(f\"(index_instance/n_instances = {index_instance}/{n_instances})\", end=\"\\r\")\n",
    "            #print(f\"np.array(p) = {np.array(p)}\")\n",
    "            X[index_instance, :length, :] = one_hot(np.array(p))#[..., np.newaxis]\n",
    "            Y[index_instance, :] = np.concatenate((np.argsort(p), np.arange(length, max_length)))\n",
    "            index_instance += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae87725",
   "metadata": {},
   "source": [
    "### Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ac10c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db648cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "X_train_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f629d758",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218739e2",
   "metadata": {},
   "source": [
    "We might be able to use less neurons and still arrive at a similar performance. Running out of time, I had not tried to tune the model; instead, I had spent most of the time trying to implement more solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d456c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"vanilla_NN_model.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d73ff0d",
   "metadata": {},
   "source": [
    "# add some callbacks before beginning training.\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"vanilla_NN_model.h5\")\n",
    "\n",
    "model.fit(X_train_val,\n",
    "         Y_train_val,\n",
    "         #steps_per_epoch=60_000,\n",
    "         epochs=3,\n",
    "         validation_split=0.2,\n",
    "         verbose=True,\n",
    "         callbacks=[checkpoint_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b748ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db66b73",
   "metadata": {},
   "source": [
    "## Evaluation on `X_test`\n",
    "We certainly would like to have performance measures like accuracy, precision/recall, etc. But we must first write some convenience functions to facilitate the operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a91c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sorter:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def lenlen(self, x):\n",
    "        somme = np.sum(x, axis=-1)\n",
    "        first_zero_index = -1\n",
    "        for i, s in enumerate(somme):\n",
    "            if s > 10**(-6):\n",
    "                first_zero_index = i\n",
    "        if first_zero_index == -1:\n",
    "            length = 10\n",
    "        else:\n",
    "            length = first_zero_index + 1\n",
    "        return length\n",
    "\n",
    "    def prettier(self, x, y):\n",
    "        \"\"\"\n",
    "        x.shape = (10,10)\n",
    "        \"\"\"\n",
    "        length = self.lenlen(x)\n",
    "        xx = np.argmax(x[:length], axis=-1)\n",
    "        sort_indices = y.astype(int)[:length]\n",
    "        yy = xx[sort_indices]\n",
    "        return xx, yy\n",
    "    \n",
    "    def evaluate(self, X, Y):\n",
    "        Y_pred = self.model.predict(X)  # of shape (n_instances, 10, 10)\n",
    "        Y = Y.astype(int)               # of shape (n_instances, 10)\n",
    "        m = X.shape[0]\n",
    "        n_correct = 0\n",
    "        for i, x in enumerate(X):\n",
    "            length = self.lenlen(x)\n",
    "            y_pred = Y_pred[i]\n",
    "            y_pred_sparse = np.argmax(y_pred, axis=-1)\n",
    "            n_correct += np.array_equal(Y[i], y_pred_sparse)\n",
    "        print(f\"acc = {n_correct/m}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b0a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorter = Sorter(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd637e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sorter.evaluate(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
